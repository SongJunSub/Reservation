# ğŸ“Š ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” JPAì™€ R2DBCë¥¼ ì‚¬ìš©í•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ì„±ëŠ¥ ë¹„êµì™€ ìµœì í™” ì „ëµì„ ë‹¤ë£¹ë‹ˆë‹¤. ì‹¤ë¬´ í™˜ê²½ì—ì„œ ë°œìƒí•˜ëŠ” ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ì— ëŒ€í•œ ê¸°ìˆ ì  ì„ íƒê³¼ êµ¬í˜„ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í•™ìŠµ ëª©í‘œ

- **ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ íŒ¨í„´**: 10ë§Œ+ ë ˆì½”ë“œ ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤
- **í˜ì´ì§• ì „ëµ ë¹„êµ**: Offset vs Cursor vs Streaming ë°©ì‹
- **ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ì²˜ë¦¬ ì†ë„ ê· í˜•
- **ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¶„ì„**: ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ ì „ëµ
- **Export/Import ì „ëµ**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì´ë™ ìµœì í™”

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

### í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì„±

```kotlin
@Component
class LargeDataProcessingComparator(
    private val jpaRepository: ReservationRepository,
    private val r2dbcRepository: ReservationRepositoryReactive
) : CommandLineRunner
```

### ì£¼ìš” êµ¬ì„± ìš”ì†Œ

1. **LargeDataProcessingComparator**: ì¢…í•©ì ì¸ ì„±ëŠ¥ ë¹„êµ ë„êµ¬
2. **DatabasePerformanceComparator**: ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ì¸¡ì •
3. **large-data-processing-test.sh**: ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

## ğŸ“Š í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### 1. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì¡°íšŒ ì„±ëŠ¥

#### JPA ëŒ€ìš©ëŸ‰ ì¡°íšŒ
```kotlin
private fun testJpaLargeRetrieval(size: Int): LargeDataTestResult {
    val startMemory = getMemoryUsage()
    val executionTime = measureTimeMillis {
        val pageable = PageRequest.of(0, size, Sort.by("id"))
        val page = jpaRepository.findAll(pageable)
        
        // ë°ì´í„° ì ‘ê·¼ìœ¼ë¡œ ì‹¤ì œ ë¡œë”© ê°•ì œ
        page.content.forEach { reservation ->
            val _ = reservation.guestName.length
        }
    }
    // ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë°˜í™˜
}
```

#### R2DBC ìŠ¤íŠ¸ë¦¬ë° ì¡°íšŒ
```kotlin
private fun testR2dbcLargeRetrieval(size: Int): LargeDataTestResult {
    val executionTime = measureTimeMillis {
        runBlocking {
            r2dbcRepository.findAll()
                .take(size.toLong())
                .collect { reservation ->
                    val _ = reservation.guestName.length
                    processedCount.incrementAndGet()
                }
        }
    }
}
```

### 2. í˜ì´ì§• ì „ëµ ë¹„êµ

#### Offset ê¸°ë°˜ í˜ì´ì§•
```kotlin
private fun testOffsetPaging(totalRecords: Int, pageSize: Int) {
    var currentPage = 0
    while (processedRecords.get() < totalRecords) {
        val pageable = PageRequest.of(currentPage, pageSize, Sort.by("id"))
        val page = jpaRepository.findAll(pageable)
        
        // Deep paging ì„±ëŠ¥ ì €í•˜ ì‹œë®¬ë ˆì´ì…˜
        if (currentPage > 100) {
            Thread.sleep(1) // ì„±ëŠ¥ ì €í•˜ ì‹œë®¬ë ˆì´ì…˜
        }
        currentPage++
    }
}
```

#### Cursor ê¸°ë°˜ í˜ì´ì§•
```kotlin
private fun testCursorPaging(totalRecords: Int, pageSize: Int) {
    var lastId = 0L
    while (processedRecords.get() < totalRecords) {
        // ID ê¸°ì¤€ cursor í˜ì´ì§•
        val reservations = jpaRepository.findAll(pageable).content
            .filter { it.id > lastId }
            .take(pageSize)
        
        reservations.forEach { reservation ->
            lastId = maxOf(lastId, reservation.id)
        }
    }
}
```

#### ìŠ¤íŠ¸ë¦¬ë° í˜ì´ì§•
```kotlin
private fun testStreamingPaging(totalRecords: Int, pageSize: Int) {
    val streamChunkSize = pageSize / 10
    val totalChunks = (totalRecords + streamChunkSize - 1) / streamChunkSize
    
    for (chunk in 0 until totalChunks) {
        // ì‘ì€ ì²­í¬ë¡œ ì—°ì† ì²˜ë¦¬
        val processingTime = Random.nextLong(1, 5)
        Thread.sleep(processingTime)
    }
}
```

### 3. ëŒ€ìš©ëŸ‰ ë°ì´í„° Insert/Update

#### JPA ë°°ì¹˜ Insert
```kotlin
@Transactional
private fun testJpaLargeInsert(size: Int): LargeDataTestResult {
    val batchSize = 1000
    val batches = (size + batchSize - 1) / batchSize

    repeat(batches) { batchIndex ->
        val batch = (1..currentBatchSize).map { i ->
            createLargeDataReservation(batchIndex * batchSize + i)
        }
        jpaRepository.saveAll(batch)
    }
}
```

#### R2DBC ë¹„ë™ê¸° Insert
```kotlin
private fun testR2dbcLargeInsert(size: Int): LargeDataTestResult {
    runBlocking {
        val batchSize = 1000
        reservations.chunked(batchSize).forEach { batch ->
            Flux.fromIterable(batch)
                .flatMap { r2dbcRepository.save(it) }
                .collectList()
                .awaitSingle()
        }
    }
}
```

### 4. ë°ì´í„° Export/Import

#### CSV Export
```kotlin
private fun testDataExport(size: Int, format: String): LargeDataTestResult {
    val reservations = jpaRepository.findAll(pageable).content
    
    FileWriter(filePath).use { writer ->
        when (format) {
            "CSV" -> {
                writer.write("id,confirmationNumber,guestName,...\n")
                reservations.forEach { reservation ->
                    writer.write("${reservation.id},${reservation.confirmationNumber},...\n")
                }
            }
            "JSON" -> {
                // JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
            }
        }
    }
}
```

### 5. ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¶„ì„

#### ì¸ë±ìŠ¤ ê¸°ë°˜ ê²€ìƒ‰
```kotlin
private fun testIndexedSearch(): LargeDataTestResult {
    repeat(searchCount) { i ->
        val email = "test${Random.nextInt(10000)}@test.com"
        val results = jpaRepository.findByGuestEmailAndStatusIn(
            email, 
            listOf(ReservationStatus.CONFIRMED, ReservationStatus.CHECKED_IN)
        )
    }
}
```

#### Full Table Scan
```kotlin
private fun testFullTableScan(): LargeDataTestResult {
    repeat(scanCount) { i ->
        // ë¹„íš¨ìœ¨ì  ì¿¼ë¦¬ë¡œ Full table scan ì‹œë®¬ë ˆì´ì…˜
        val searchTerm = "Guest ${Random.nextInt(1000)}"
        val allReservations = jpaRepository.findAll()
        val filtered = allReservations.filter { 
            it.guestName.contains(searchTerm, ignoreCase = true) 
        }
    }
}
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. ëª…ë ¹í–‰ ë„êµ¬ ì‹¤í–‰

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
./scripts/large-data-processing-test.sh full --build --report

# í˜ì´ì§• ì „ëµë§Œ í…ŒìŠ¤íŠ¸
./scripts/large-data-processing-test.sh paging --data-size 50000

# ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
./scripts/large-data-processing-test.sh memory --report
```

### 2. í”„ë¡œê·¸ë˜ë§¤í‹± ì‹¤í–‰

```kotlin
@Autowired
private lateinit var largeDataComparator: LargeDataProcessingComparator

fun runLargeDataTest() {
    largeDataComparator.runLargeDataProcessingComparison()
}
```

### 3. Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰

```bash
./gradlew bootRun --args="--large-data-processing --data-size=100000"
```

## ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­

### ì£¼ìš” ì¸¡ì • ì§€í‘œ

```kotlin
data class LargeDataTestResult(
    val testName: String,
    val technology: String,
    val dataSize: Int,
    val executionTimeMs: Long,
    val throughputPerSecond: Double,
    val memoryUsedMB: Long,
    val peakMemoryMB: Long,
    val ioOperations: Long,
    val gcCount: Int,
    val errorCount: Int = 0
) {
    fun getProcessingRate(): Double = 
        if (executionTimeMs > 0) (dataSize * 1000.0) / executionTimeMs else 0.0
    
    fun getEfficiencyScore(): Double {
        val throughputScore = minOf(throughputPerSecond / 1000.0, 1.0) * 40
        val memoryScore = maxOf(0.0, 1.0 - (memoryUsedMB / 1000.0)) * 30
        val stabilityScore = maxOf(0.0, 1.0 - (errorCount / dataSize.toDouble())) * 30
        return throughputScore + memoryScore + stabilityScore
    }
}
```

### ì„±ëŠ¥ ë¶„ì„ ì˜ˆì‹œ

```
ğŸ“Š JPA:
  ë°ì´í„° í¬ê¸°: 100000ê°œ
  ì‹¤í–‰ ì‹œê°„: 12500ms
  ì²˜ë¦¬ìœ¨: 8000.0 records/sec
  ë©”ëª¨ë¦¬ ì‚¬ìš©: 450MB (ìµœëŒ€: 520MB)
  íš¨ìœ¨ì„± ì ìˆ˜: 85.5/100

ğŸ“Š R2DBC:
  ë°ì´í„° í¬ê¸°: 100000ê°œ
  ì‹¤í–‰ ì‹œê°„: 8500ms
  ì²˜ë¦¬ìœ¨: 11764.7 records/sec
  ë©”ëª¨ë¦¬ ì‚¬ìš©: 280MB (ìµœëŒ€: 320MB)
  íš¨ìœ¨ì„± ì ìˆ˜: 92.3/100
```

## ğŸ¯ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### JPA ìµœì í™”

#### 1. ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
```properties
# application.yml
spring:
  jpa:
    properties:
      hibernate:
        jdbc:
          batch_size: 1000
        order_inserts: true
        order_updates: true
        batch_versioned_data: true
```

#### 2. ì—°ê´€ê´€ê³„ ìµœì í™”
```kotlin
@Entity
class Reservation {
    @ManyToOne(fetch = FetchType.LAZY)
    @JoinColumn(name = "guest_id")
    val guest: Guest? = null
    
    @OneToMany(mappedBy = "reservation", fetch = FetchType.LAZY)
    val payments: List<Payment> = emptyList()
}
```

#### 3. ì¿¼ë¦¬ ìµœì í™”
```kotlin
interface ReservationRepository : JpaRepository<Reservation, Long> {
    
    @Query("FROM Reservation r JOIN FETCH r.guest WHERE r.status IN :statuses")
    fun findByStatusInWithGuest(@Param("statuses") statuses: List<ReservationStatus>): List<Reservation>
    
    @Modifying
    @Query("UPDATE Reservation SET status = :status WHERE id IN :ids")
    fun updateStatusBatch(@Param("status") status: ReservationStatus, @Param("ids") ids: List<Long>)
}
```

### R2DBC ìµœì í™”

#### 1. ì—°ê²° í’€ ì„¤ì •
```yaml
spring:
  r2dbc:
    pool:
      initial-size: 10
      max-size: 50
      max-idle-time: 30m
      validation-query: SELECT 1
```

#### 2. ë°±í”„ë ˆì…” ì „ëµ
```kotlin
fun processLargeDataWithBackpressure(): Flux<ProcessedData> {
    return r2dbcRepository.findAll()
        .buffer(1000) // 1000ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬
        .flatMap { batch ->
            processBatch(batch)
                .onErrorResume { error ->
                    logger.error("Batch processing failed", error)
                    Mono.empty()
                }
        }
        .onBackpressureBuffer(10000) // ë°±í”„ë ˆì…” ë²„í¼ ì„¤ì •
}
```

#### 3. ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
```kotlin
fun streamLargeDataset(): Flow<Reservation> = flow {
    var offset = 0L
    val batchSize = 1000
    
    while (true) {
        val batch = r2dbcRepository.findAllWithOffset(offset, batchSize)
            .collectList()
            .awaitSingle()
        
        if (batch.isEmpty()) break
        
        batch.forEach { reservation ->
            emit(reservation)
        }
        
        offset += batchSize
    }
}
```

## ğŸ“ˆ í˜ì´ì§• ì „ëµ ì„ íƒ ê°€ì´ë“œ

### Offset ê¸°ë°˜ í˜ì´ì§•

**ì‚¬ìš© ì‹œê¸°:**
- ì†Œê·œëª¨ ë°ì´í„°ì…‹ (< 10,000 ë ˆì½”ë“œ)
- ì„ì˜ í˜ì´ì§€ ì ‘ê·¼ì´ í•„ìš”í•œ ê²½ìš°
- ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ì—ì„œ í˜ì´ì§€ ë²ˆí˜¸ê°€ í•„ìš”í•œ ê²½ìš°

**ì¥ì :**
- êµ¬í˜„ì´ ê°„ë‹¨í•¨
- ì„ì˜ í˜ì´ì§€ ì ‘ê·¼ ê°€ëŠ¥
- ì´ ë ˆì½”ë“œ ìˆ˜ ê³„ì‚° ìš©ì´

**ë‹¨ì :**
- ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ ì €í•˜ (Deep Paging ë¬¸ì œ)
- ë°ì´í„° ë³€ê²½ ì‹œ ì¤‘ë³µ/ëˆ„ë½ ê°€ëŠ¥ì„±

```kotlin
// Offset ê¸°ë°˜ êµ¬í˜„
val pageable = PageRequest.of(pageNumber, pageSize, Sort.by("id"))
val page = repository.findAll(pageable)
```

### Cursor ê¸°ë°˜ í˜ì´ì§•

**ì‚¬ìš© ì‹œê¸°:**
- ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ (> 100,000 ë ˆì½”ë“œ)
- ìˆœì°¨ì  ë°ì´í„° ì ‘ê·¼
- ì‹¤ì‹œê°„ ë°ì´í„° í”¼ë“œ

**ì¥ì :**
- ì¼ê´€ëœ ì„±ëŠ¥ ë³´ì¥
- ë°ì´í„° ë³€ê²½ì— ì•ˆì •ì 
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

**ë‹¨ì :**
- ì„ì˜ í˜ì´ì§€ ì ‘ê·¼ ë¶ˆê°€
- êµ¬í˜„ ë³µì¡ë„ ì¦ê°€
- ì •ë ¬ ê¸°ì¤€ ì»¬ëŸ¼ì´ ê³ ìœ í•´ì•¼ í•¨

```kotlin
// Cursor ê¸°ë°˜ êµ¬í˜„
fun findAfterCursor(cursor: Long, limit: Int): List<Reservation> {
    return repository.findByIdGreaterThanOrderById(cursor, PageRequest.of(0, limit))
}
```

### ìŠ¤íŠ¸ë¦¬ë° í˜ì´ì§•

**ì‚¬ìš© ì‹œê¸°:**
- ë§¤ìš° í° ë°ì´í„°ì…‹ (> 1,000,000 ë ˆì½”ë“œ)
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­
- ë©”ëª¨ë¦¬ ì œì•½ì´ í° í™˜ê²½

**ì¥ì :**
- ìµœê³ ì˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥
- ë°±í”„ë ˆì…” ìë™ ì²˜ë¦¬

**ë‹¨ì :**
- ê°€ì¥ ë³µì¡í•œ êµ¬í˜„
- ì—ëŸ¬ ì²˜ë¦¬ ë³µì¡
- ìƒíƒœ ê´€ë¦¬ í•„ìš”

```kotlin
// ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„
fun streamAll(): Flow<Reservation> = flow {
    val chunkSize = 1000
    var processed = 0
    
    while (true) {
        val chunk = repository.findChunk(processed, chunkSize)
        if (chunk.isEmpty()) break
        
        chunk.forEach { emit(it) }
        processed += chunk.size
    }
}
```

## ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„

### ì‘ì€ ë°°ì¹˜ vs í° ë°°ì¹˜

#### ì‘ì€ ë°°ì¹˜ (100-500ê°œ)
```kotlin
private fun testSmallBatchMemoryPattern(): LargeDataTestResult {
    val batchSize = 100
    val totalBatches = 500
    
    repeat(totalBatches) { batchIndex ->
        val batch = repository.findPage(batchIndex, batchSize)
        processBatch(batch)
        
        // ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
        if (batchIndex % 50 == 0) {
            System.gc()
        }
    }
}
```

**íŠ¹ì§•:**
- ì•ˆì •ì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- ë¹ˆë²ˆí•œ I/O ì‘ì—…
- ë†’ì€ ì•ˆì •ì„±

#### í° ë°°ì¹˜ (5000-10000ê°œ)
```kotlin
private fun testLargeBatchMemoryPattern(): LargeDataTestResult {
    val batchSize = 5000
    val totalBatches = 10
    
    repeat(totalBatches) { batchIndex ->
        val batch = repository.findPage(batchIndex, batchSize)
        processBatch(batch)
        
        // ë°°ì¹˜ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
        System.gc()
    }
}
```

**íŠ¹ì§•:**
- ë†’ì€ ì²˜ë¦¬ ì†ë„
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë³€ë™ì´ í¼
- I/O íšŸìˆ˜ ìµœì†Œí™”

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

```kotlin
private fun getMemoryUsage(): Long {
    val runtime = Runtime.getRuntime()
    return (runtime.totalMemory() - runtime.freeMemory()) / (1024 * 1024)
}

private fun getPeakMemoryUsage(): Long {
    val memoryMXBean = ManagementFactory.getMemoryMXBean()
    return memoryMXBean.heapMemoryUsage.max / (1024 * 1024)
}
```

## ğŸ” ì¸ë±ìŠ¤ ì„±ëŠ¥ ìµœì í™”

### ì¸ë±ìŠ¤ ì„¤ê³„ ì›ì¹™

1. **ì„ íƒë„ê°€ ë†’ì€ ì»¬ëŸ¼**: ê³ ìœ í•œ ê°’ì´ ë§ì€ ì»¬ëŸ¼
2. **ìì£¼ ì‚¬ìš©ë˜ëŠ” WHERE ì¡°ê±´**: ê²€ìƒ‰ ë¹ˆë„ê°€ ë†’ì€ ì»¬ëŸ¼
3. **ORDER BY ì ˆ**: ì •ë ¬ì— ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼

### ë³µí•© ì¸ë±ìŠ¤ ì „ëµ

```sql
-- íš¨ê³¼ì ì¸ ë³µí•© ì¸ë±ìŠ¤
CREATE INDEX idx_reservation_status_date 
ON reservations (status, check_in_date, guest_email);

-- ì»¤ë²„ë§ ì¸ë±ìŠ¤ (ì¸ë±ìŠ¤ë§Œìœ¼ë¡œ ì¿¼ë¦¬ ì²˜ë¦¬)
CREATE INDEX idx_reservation_covering 
ON reservations (status, guest_email) 
INCLUDE (guest_name, total_amount);
```

### ì¸ë±ìŠ¤ ì„±ëŠ¥ ì¸¡ì •

```kotlin
@Transactional(readOnly = true)
fun compareIndexPerformance() {
    // ì¸ë±ìŠ¤ ê¸°ë°˜ ê²€ìƒ‰
    val indexedTime = measureTimeMillis {
        repository.findByGuestEmailAndStatusIn(email, statuses)
    }
    
    // Full table scan
    val scanTime = measureTimeMillis {
        repository.findAll().filter { 
            it.guestEmail == email && it.status in statuses 
        }
    }
    
    println("ì¸ë±ìŠ¤ ê²€ìƒ‰: ${indexedTime}ms")
    println("Full scan: ${scanTime}ms")
    println("ì„±ëŠ¥ ê°œì„ : ${scanTime / indexedTime}ë°°")
}
```

## ğŸ“¤ğŸ“¥ Export/Import ìµœì í™”

### CSV Export ìµœì í™”

```kotlin
fun exportToCsv(reservations: List<Reservation>, filePath: String) {
    BufferedWriter(FileWriter(filePath)).use { writer ->
        // í—¤ë” ì‘ì„±
        writer.write("id,guest_name,guest_email,check_in_date,total_amount\n")
        
        // ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ì„±
        reservations.chunked(1000).forEach { chunk ->
            val csvLines = chunk.joinToString("\n") { reservation ->
                "${reservation.id},\"${reservation.guestName}\"," +
                "${reservation.guestEmail},${reservation.checkInDate},${reservation.totalAmount}"
            }
            writer.write(csvLines + "\n")
        }
    }
}
```

### JSON Export ìµœì í™”

```kotlin
fun exportToJson(reservations: List<Reservation>, filePath: String) {
    val objectMapper = ObjectMapper()
    
    FileOutputStream(filePath).use { output ->
        JsonGenerator generator = objectMapper.factory.createGenerator(output)
        generator.writeStartArray()
        
        reservations.chunked(1000).forEach { chunk ->
            chunk.forEach { reservation ->
                generator.writeObject(reservation)
            }
            generator.flush() // ì£¼ê¸°ì ìœ¼ë¡œ í”ŒëŸ¬ì‹œ
        }
        
        generator.writeEndArray()
        generator.close()
    }
}
```

### ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•œ ì„±ëŠ¥ í–¥ìƒ

```kotlin
fun parallelExport(reservations: List<Reservation>, filePath: String) {
    val chunkSize = 10000
    val chunks = reservations.chunked(chunkSize)
    
    runBlocking {
        val results = chunks.mapIndexed { index, chunk ->
            async(Dispatchers.IO) {
                val tempFile = "${filePath}_part_${index}.csv"
                exportChunkToCsv(chunk, tempFile)
                tempFile
            }
        }.awaitAll()
        
        // ê²°ê³¼ íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ ë³‘í•©
        mergeFiles(results, filePath)
    }
}
```

## ğŸ¯ ì‹¤ë¬´ ê¶Œì¥ì‚¬í•­

### ê¸°ìˆ  ì„ íƒ ë§¤íŠ¸ë¦­ìŠ¤

| ìƒí™© | ë°ì´í„° í¬ê¸° | ë™ì‹œì„± | ë³µì¡ë„ | ê¶Œì¥ ê¸°ìˆ  | ì´ìœ  |
|------|-------------|--------|--------|-----------|------|
| ë°°ì¹˜ ì²˜ë¦¬ | > 100ë§Œ | ë‚®ìŒ | ë†’ìŒ | JPA | íŠ¸ëœì­ì…˜ ì•ˆì •ì„± |
| ì‹¤ì‹œê°„ ì¡°íšŒ | > 10ë§Œ | ë†’ìŒ | ì¤‘ê°„ | R2DBC | ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± |
| ëŒ€ìš©ëŸ‰ Export | > 50ë§Œ | ë‚®ìŒ | ë‚®ìŒ | JPA + Streaming | ì•ˆì •ì ì¸ ì²˜ë¦¬ |
| ì‹¤ì‹œê°„ í”¼ë“œ | ë¬´ì œí•œ | ë†’ìŒ | ë†’ìŒ | R2DBC + Flow | ë°±í”„ë ˆì…” ì§€ì› |

### ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

#### JPA ìµœì í™”
- [ ] ë°°ì¹˜ í¬ê¸° ì„¤ì • (`hibernate.jdbc.batch_size`)
- [ ] 2ì°¨ ìºì‹œ í™œìš© (`@Cacheable`)
- [ ] N+1 ë¬¸ì œ í•´ê²° (`@EntityGraph`, Fetch Join)
- [ ] ì§€ì—° ë¡œë”© ì „ëµ ì ìš©
- [ ] ì½ê¸° ì „ìš© íŠ¸ëœì­ì…˜ ì‚¬ìš© (`@Transactional(readOnly = true)`)

#### R2DBC ìµœì í™”
- [ ] ì—°ê²° í’€ í¬ê¸° ì¡°ì •
- [ ] ë°±í”„ë ˆì…” ì „ëµ êµ¬í˜„
- [ ] ì ì ˆí•œ ë²„í¼ í¬ê¸° ì„¤ì •
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

#### ê³µí†µ ìµœì í™”
- [ ] ì ì ˆí•œ ì¸ë±ìŠ¤ ì„¤ê³„
- [ ] ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- [ ] GC íŠœë‹
- [ ] ë„¤íŠ¸ì›Œí¬ I/O ìµœì í™”

### ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

```kotlin
@Component
class PerformanceMonitor {
    
    @EventListener
    fun onLargeDataProcessingStart(event: ProcessingStartEvent) {
        // ì²˜ë¦¬ ì‹œì‘ ë©”íŠ¸ë¦­ ê¸°ë¡
        Metrics.counter("large.data.processing.start").increment()
    }
    
    @EventListener  
    fun onLargeDataProcessingComplete(event: ProcessingCompleteEvent) {
        // ì²˜ë¦¬ ì™„ë£Œ ë©”íŠ¸ë¦­ ê¸°ë¡
        Metrics.timer("large.data.processing.duration")
            .record(event.duration, TimeUnit.MILLISECONDS)
            
        // ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì•Œë¦¼
        if (event.duration > Duration.ofMinutes(10)) {
            alertService.sendSlowProcessingAlert(event)
        }
    }
}
```

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. OutOfMemoryError
**ì›ì¸:** ë„ˆë¬´ í° ë°°ì¹˜ í¬ê¸° ë˜ëŠ” ë©”ëª¨ë¦¬ ëˆ„ìˆ˜

**í•´ê²°ì±…:**
```kotlin
// ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
val batchSize = if (availableMemory < 1024) 100 else 1000

// ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
if (processedCount % 10000 == 0) {
    System.gc()
    Thread.sleep(100)
}
```

#### 2. ëŠë¦° Deep Paging
**ì›ì¸:** OFFSETì´ í° ê²½ìš° ì„±ëŠ¥ ì €í•˜

**í•´ê²°ì±…:**
```kotlin
// Cursor ê¸°ë°˜ í˜ì´ì§•ìœ¼ë¡œ ë³€ê²½
fun findAfterId(lastId: Long, limit: Int): List<Reservation> {
    return repository.findByIdGreaterThanOrderById(lastId, 
        PageRequest.of(0, limit))
}
```

#### 3. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê³ ê°ˆ
**ì›ì¸:** ì—°ê²° í’€ í¬ê¸°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì—°ê²° ëˆ„ìˆ˜

**í•´ê²°ì±…:**
```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 50
      minimum-idle: 10
      connection-timeout: 20000
      idle-timeout: 300000
```

#### 4. GC ì˜¤ë²„í—¤ë“œ
**ì›ì¸:** ë¹ˆë²ˆí•œ ëŒ€ìš©ëŸ‰ ê°ì²´ ìƒì„±

**í•´ê²°ì±…:**
```kotlin
// ê°ì²´ ì¬ì‚¬ìš©
private val reservationBuilder = Reservation.builder()

// ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ
fun processLargeDataStream(): Flow<ProcessedResult> = flow {
    repository.findAllAsFlow()
        .buffer(1000)
        .collect { batch ->
            val result = processBatch(batch)
            emit(result)
        }
}
```

## ğŸ“š ì¶”ê°€ ìë£Œ

### ê´€ë ¨ ë¬¸ì„œ
- [Database Performance Comparator Guide](database-performance-guide.md)
- [JPA Best Practices](jpa-best-practices.md)
- [R2DBC Reactive Programming Guide](r2dbc-guide.md)

### ì™¸ë¶€ ë¦¬ì†ŒìŠ¤
- [Hibernate Performance Tuning](https://hibernate.org/orm/documentation/)
- [Spring Data R2DBC Reference](https://docs.spring.io/spring-data/r2dbc/docs/current/reference/html/)
- [Database Indexing Strategies](https://use-the-index-luke.com/)

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬
- [JMH (Java Microbenchmark Harness)](https://openjdk.java.net/projects/code-tools/jmh/)
- [Spring Boot Actuator](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html)
- [Micrometer Metrics](https://micrometer.io/)

---

*ì´ ê°€ì´ë“œëŠ” ì‹¤ì œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.*