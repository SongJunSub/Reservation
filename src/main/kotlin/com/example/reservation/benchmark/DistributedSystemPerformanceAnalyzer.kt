package com.example.reservation.benchmark

import kotlinx.coroutines.*
import kotlinx.coroutines.flow.*
import org.springframework.stereotype.Component
import java.time.Duration
import java.time.Instant
import java.time.LocalDateTime
import java.util.concurrent.ConcurrentHashMap
import java.util.concurrent.atomic.AtomicLong
import kotlin.math.*
import kotlin.system.measureTimeMillis

/**
 * ğŸŒ Distributed System Performance Analyzer
 * 
 * ë¶„ì‚° ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
 * ë¡œë“œ ë°¸ëŸ°ì‹±, ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”©, ë¶„ì‚° ìºì‹œ, ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í†µì‹  ë“±ì„ ë¶„ì„í•©ë‹ˆë‹¤.
 */
@Component
class DistributedSystemPerformanceAnalyzer {

    companion object {
        private const val DEFAULT_TEST_DURATION_SECONDS = 300 // 5ë¶„
        private const val DEFAULT_CONCURRENT_REQUESTS = 100
        private const val WARMUP_DURATION_SECONDS = 60 // 1ë¶„
    }

    /**
     * ì¢…í•© ë¶„ì‚° ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰
     */
    suspend fun runComprehensiveAnalysis(): ComprehensiveDistributedAnalysisResult {
        println("ğŸš€ Starting Comprehensive Distributed System Performance Analysis")
        val startTime = System.currentTimeMillis()
        
        val loadBalancingResult = analyzeLoadBalancing()
        val databaseShardingResult = analyzeDatabaseSharding()
        val distributedCacheResult = analyzeDistributedCache()
        val microserviceCommunicationResult = analyzeMicroserviceCommunication()
        val systemResilienceResult = analyzeSystemResilience()
        
        val totalTime = System.currentTimeMillis() - startTime
        
        val overallAnalysis = generateOverallAnalysis(
            loadBalancingResult,
            databaseShardingResult,
            distributedCacheResult,
            microserviceCommunicationResult,
            systemResilienceResult
        )
        
        println("âœ… Comprehensive distributed system analysis completed in ${totalTime}ms")
        
        return ComprehensiveDistributedAnalysisResult(
            loadBalancing = loadBalancingResult,
            databaseSharding = databaseShardingResult,
            distributedCache = distributedCacheResult,
            microserviceCommunication = microserviceCommunicationResult,
            systemResilience = systemResilienceResult,
            overallAnalysis = overallAnalysis,
            executionTimeMs = totalTime
        )
    }

    /**
     * 1ë‹¨ê³„: ë¡œë“œ ë°¸ëŸ°ì‹± ì „ëµ ë¶„ì„
     */
    suspend fun analyzeLoadBalancing(): LoadBalancingAnalysisResult = withContext(Dispatchers.IO) {
        println("ğŸ” Phase 1: Load Balancing Strategy Analysis")
        
        val strategies = listOf(
            LoadBalancingStrategy("RoundRobin", LoadBalancingType.ROUND_ROBIN),
            LoadBalancingStrategy("WeightedRoundRobin", LoadBalancingType.WEIGHTED_ROUND_ROBIN),
            LoadBalancingStrategy("LeastConnections", LoadBalancingType.LEAST_CONNECTIONS),
            LoadBalancingStrategy("LeastResponseTime", LoadBalancingType.LEAST_RESPONSE_TIME),
            LoadBalancingStrategy("IPHash", LoadBalancingType.IP_HASH),
            LoadBalancingStrategy("Random", LoadBalancingType.RANDOM)
        )
        
        val results = mutableMapOf<String, LoadBalancingMetrics>()
        
        for (strategy in strategies) {
            println("ğŸ“Š Testing ${strategy.name} load balancing strategy...")
            results[strategy.name] = measureLoadBalancingPerformance(strategy)
        }
        
        val analysis = analyzeLoadBalancingResults(results)
        println("âœ… Load balancing analysis completed")
        
        LoadBalancingAnalysisResult(
            strategies = results,
            analysis = analysis,
            recommendations = generateLoadBalancingRecommendations(results)
        )
    }

    private suspend fun measureLoadBalancingPerformance(strategy: LoadBalancingStrategy): LoadBalancingMetrics {
        val serverNodes = createTestServerNodes(5) // 5ê°œ ì„œë²„ ë…¸ë“œ ì‹œë®¬ë ˆì´ì…˜
        val loadBalancer = createLoadBalancer(strategy, serverNodes)
        
        val requests = (1..1000).map { TestRequest(id = it, size = kotlin.random.Random.nextInt(1024, 8192)) }
        val results = mutableListOf<RequestResult>()
        
        // ì›Œë°ì—…
        repeat(100) {
            loadBalancer.routeRequest(TestRequest(id = it, size = 1024))
        }
        
        // ì‹¤ì œ ì¸¡ì •
        val startTime = System.currentTimeMillis()
        
        requests.asFlow()
            .buffer(50) // ë™ì‹œ ìš”ì²­ ì œí•œ
            .map { request ->
                async {
                    val requestStartTime = System.nanoTime()
                    val result = loadBalancer.routeRequest(request)
                    val requestEndTime = System.nanoTime()
                    
                    RequestResult(
                        requestId = request.id,
                        serverNode = result.serverNode,
                        responseTimeNanos = requestEndTime - requestStartTime,
                        success = result.success
                    )
                }
            }
            .buffer(100)
            .collect { deferred ->
                results.add(deferred.await())
            }
        
        val endTime = System.currentTimeMillis()
        val totalDurationMs = endTime - startTime
        
        return calculateLoadBalancingMetrics(results, totalDurationMs, serverNodes)
    }

    private fun createTestServerNodes(count: Int): List<ServerNode> {
        return (1..count).map { nodeId ->
            ServerNode(
                id = "server-$nodeId",
                weight = when (nodeId) {
                    1 -> 1.0 // ë‚®ì€ ì„±ëŠ¥ ì„œë²„
                    2, 3 -> 2.0 // ì¤‘ê°„ ì„±ëŠ¥ ì„œë²„
                    else -> 3.0 // ë†’ì€ ì„±ëŠ¥ ì„œë²„
                },
                capacity = nodeId * 100,
                currentConnections = 0,
                averageResponseTimeMs = when (nodeId) {
                    1 -> 150.0
                    2, 3 -> 100.0
                    else -> 50.0
                }
            )
        }
    }

    private fun createLoadBalancer(strategy: LoadBalancingStrategy, nodes: List<ServerNode>): LoadBalancer {
        return when (strategy.type) {
            LoadBalancingType.ROUND_ROBIN -> RoundRobinLoadBalancer(nodes)
            LoadBalancingType.WEIGHTED_ROUND_ROBIN -> WeightedRoundRobinLoadBalancer(nodes)
            LoadBalancingType.LEAST_CONNECTIONS -> LeastConnectionsLoadBalancer(nodes)
            LoadBalancingType.LEAST_RESPONSE_TIME -> LeastResponseTimeLoadBalancer(nodes)
            LoadBalancingType.IP_HASH -> IPHashLoadBalancer(nodes)
            LoadBalancingType.RANDOM -> RandomLoadBalancer(nodes)
        }
    }

    private fun calculateLoadBalancingMetrics(
        results: List<RequestResult>,
        totalDurationMs: Long,
        serverNodes: List<ServerNode>
    ): LoadBalancingMetrics {
        val successfulResults = results.filter { it.success }
        val responseTimes = successfulResults.map { it.responseTimeNanos / 1_000_000.0 } // msë¡œ ë³€í™˜
        
        // ì„œë²„ë³„ ìš”ì²­ ë¶„ë°° ë¶„ì„
        val serverDistribution = results.groupBy { it.serverNode }.mapValues { it.value.size }
        val idealDistribution = results.size.toDouble() / serverNodes.size
        val distributionVariance = serverDistribution.values.map { 
            (it - idealDistribution).pow(2) 
        }.average()
        val distributionEfficiency = 100.0 - (distributionVariance / idealDistribution * 100).coerceAtMost(100.0)
        
        return LoadBalancingMetrics(
            throughputRps = successfulResults.size.toDouble() / (totalDurationMs / 1000.0),
            averageLatencyMs = responseTimes.average(),
            distributionEfficiency = distributionEfficiency,
            failoverTimeMs = measureFailoverTime(serverNodes),
            healthCheckLatencyMs = measureHealthCheckLatency(serverNodes)
        )
    }

    private fun measureFailoverTime(serverNodes: List<ServerNode>): Long {
        // ì„œë²„ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜ ë° failover ì‹œê°„ ì¸¡ì •
        val startTime = System.nanoTime()
        
        // ì²« ë²ˆì§¸ ì„œë²„ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜
        val failedNode = serverNodes.first()
        failedNode.isHealthy = false
        
        // ìƒˆë¡œìš´ ìš”ì²­ì´ ë‹¤ë¥¸ ì„œë²„ë¡œ ë¼ìš°íŒ…ë˜ëŠ” ì‹œê°„ ì¸¡ì •
        val testRequest = TestRequest(id = 9999, size = 1024)
        val loadBalancer = RoundRobinLoadBalancer(serverNodes.filter { it.isHealthy })
        loadBalancer.routeRequest(testRequest)
        
        val endTime = System.nanoTime()
        
        // ì„œë²„ ë³µêµ¬
        failedNode.isHealthy = true
        
        return (endTime - startTime) / 1_000_000 // msë¡œ ë³€í™˜
    }

    private fun measureHealthCheckLatency(serverNodes: List<ServerNode>): Double {
        val healthCheckTimes = serverNodes.map {
            val startTime = System.nanoTime()
            val isHealthy = performHealthCheck(it)
            val endTime = System.nanoTime()
            (endTime - startTime) / 1_000_000.0 // msë¡œ ë³€í™˜
        }
        
        return healthCheckTimes.average()
    }

    private fun performHealthCheck(node: ServerNode): Boolean {
        // í—¬ìŠ¤ì²´í¬ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” HTTP ìš”ì²­ì´ë‚˜ TCP ì—°ê²° í™•ì¸)
        Thread.sleep(kotlin.random.Random.nextLong(1, 10)) // 1-10ms ì‹œë®¬ë ˆì´ì…˜
        return node.isHealthy
    }

    private fun analyzeLoadBalancingResults(results: Map<String, LoadBalancingMetrics>): LoadBalancingAnalysis {
        val bestThroughput = results.maxByOrNull { it.value.throughputRps }
        val bestLatency = results.minByOrNull { it.value.averageLatencyMs }
        val bestDistribution = results.maxByOrNull { it.value.distributionEfficiency }
        
        val overallScore = results.mapValues { (_, metrics) ->
            val throughputScore = metrics.throughputRps / results.values.maxOf { it.throughputRps }
            val latencyScore = 1.0 - (metrics.averageLatencyMs / results.values.maxOf { it.averageLatencyMs })
            val distributionScore = metrics.distributionEfficiency / 100.0
            
            (throughputScore * 0.4 + latencyScore * 0.3 + distributionScore * 0.3)
        }
        
        val bestOverall = overallScore.maxByOrNull { it.value }
        
        return LoadBalancingAnalysis(
            bestStrategy = bestOverall?.key ?: "WeightedRoundRobin",
            worstStrategy = overallScore.minByOrNull { it.value }?.key ?: "Random",
            overallRecommendation = when (bestOverall?.key) {
                "WeightedRoundRobin" -> "ì„œë²„ ì„±ëŠ¥ ì°¨ì´ê°€ ìˆëŠ” í™˜ê²½ì—ì„œëŠ” ê°€ì¤‘ ë¼ìš´ë“œë¡œë¹ˆì´ ìµœì ì…ë‹ˆë‹¤"
                "LeastConnections" -> "ì—°ê²° ìˆ˜ ê¸°ë°˜ ë¶„ì‚°ì´ í˜„ì¬ ì›Œí¬ë¡œë“œì— ê°€ì¥ ì í•©í•©ë‹ˆë‹¤"
                "LeastResponseTime" -> "ì‘ë‹µì‹œê°„ ê¸°ë°˜ ë¶„ì‚°ìœ¼ë¡œ ìµœì ì˜ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤"
                else -> "í˜„ì¬ í™˜ê²½ì—ì„œëŠ” ${bestOverall?.key} ì „ëµì´ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤"
            }
        )
    }

    private fun generateLoadBalancingRecommendations(results: Map<String, LoadBalancingMetrics>): List<String> {
        val recommendations = mutableListOf<String>()
        
        val avgThroughput = results.values.map { it.throughputRps }.average()
        val avgLatency = results.values.map { it.averageLatencyMs }.average()
        val avgDistribution = results.values.map { it.distributionEfficiency }.average()
        
        if (avgDistribution < 80.0) {
            recommendations.add("ì„œë²„ ê°„ ìš”ì²­ ë¶„ë°°ê°€ ë¶ˆê· ë“±í•©ë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë¡œë“œ ë°¸ëŸ°ì‹±ì„ ê³ ë ¤í•˜ì„¸ìš”")
        }
        
        if (avgLatency > 100.0) {
            recommendations.add("í‰ê·  ì§€ì—°ì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤. ì‘ë‹µì‹œê°„ ê¸°ë°˜ ë¡œë“œ ë°¸ëŸ°ì‹±ì„ í™œìš©í•˜ì„¸ìš”")
        }
        
        if (results.values.any { it.failoverTimeMs > 1000 }) {
            recommendations.add("ì¥ì•  ë³µêµ¬ ì‹œê°„ì´ ê¹ë‹ˆë‹¤. í—¬ìŠ¤ì²´í¬ ì£¼ê¸°ë¥¼ ë‹¨ì¶•í•˜ê³  ë¹ ë¥¸ ì¥ì•  ê°ì§€ë¥¼ êµ¬í˜„í•˜ì„¸ìš”")
        }
        
        recommendations.add("ì •ê¸°ì ì¸ ë¡œë“œ ë°¸ëŸ°ì‹± ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ìµœì  ì „ëµì„ ìœ ì§€í•˜ì„¸ìš”")
        
        return recommendations
    }

    /**
     * 2ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© ì„±ëŠ¥ ì¸¡ì •
     */
    suspend fun analyzeDatabaseSharding(): DatabaseShardingAnalysisResult = withContext(Dispatchers.IO) {
        println("ğŸ” Phase 2: Database Sharding Performance Analysis")
        
        val shardingStrategies = listOf(
            ShardingStrategy("RangeSharding", ShardingType.RANGE_BASED),
            ShardingStrategy("HashSharding", ShardingType.HASH_BASED),
            ShardingStrategy("DirectorySharding", ShardingType.DIRECTORY_BASED),
            ShardingStrategy("ConsistentHashSharding", ShardingType.CONSISTENT_HASH),
            ShardingStrategy("CompositeSharding", ShardingType.COMPOSITE)
        )
        
        val results = mutableMapOf<String, DatabaseShardingMetrics>()
        
        for (strategy in shardingStrategies) {
            println("ğŸ“Š Testing ${strategy.name} sharding strategy...")
            results[strategy.name] = measureShardingPerformance(strategy)
        }
        
        val analysis = analyzeShardingResults(results)
        println("âœ… Database sharding analysis completed")
        
        DatabaseShardingAnalysisResult(
            strategies = results,
            analysis = analysis,
            recommendations = generateShardingRecommendations(results)
        )
    }

    private suspend fun measureShardingPerformance(strategy: ShardingStrategy): DatabaseShardingMetrics {
        val shards = createTestShards(4) // 4ê°œ ìƒ¤ë“œë¡œ êµ¬ì„±
        val shardingRouter = createShardingRouter(strategy, shards)
        
        // ë‹¤ì–‘í•œ ì¿¼ë¦¬ íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜
        val queries = generateTestQueries(2000)
        val results = mutableListOf<QueryResult>()
        
        // ì›Œë°ì—…
        repeat(200) {
            val warmupQuery = DatabaseQuery(
                id = "warmup-$it",
                type = QueryType.SELECT,
                shardKey = "user-${kotlin.random.Random.nextInt(1, 1000)}",
                affectedShards = 1
            )
            shardingRouter.routeQuery(warmupQuery)
        }
        
        // ì‹¤ì œ ì¸¡ì •
        val startTime = System.currentTimeMillis()
        
        queries.asFlow()
            .buffer(100) // ë™ì‹œ ì¿¼ë¦¬ ì œí•œ
            .map { query ->
                async {
                    val queryStartTime = System.nanoTime()
                    val result = shardingRouter.routeQuery(query)
                    val queryEndTime = System.nanoTime()
                    
                    QueryResult(
                        queryId = query.id,
                        affectedShards = result.affectedShards,
                        executionTimeNanos = queryEndTime - queryStartTime,
                        success = result.success,
                        crossShardOperation = result.affectedShards.size > 1
                    )
                }
            }
            .buffer(200)
            .collect { deferred ->
                results.add(deferred.await())
            }
        
        val endTime = System.currentTimeMillis()
        val totalDurationMs = endTime - startTime
        
        return calculateShardingMetrics(results, totalDurationMs, shards)
    }

    private fun createTestShards(count: Int): List<DatabaseShard> {
        return (1..count).map { shardId ->
            DatabaseShard(
                id = "shard-$shardId",
                partitionRange = when (count) {
                    4 -> when (shardId) {
                        1 -> "0000-2499"
                        2 -> "2500-4999"
                        3 -> "5000-7499"
                        else -> "7500-9999"
                    }
                    else -> "$shardId"
                },
                capacity = 10000,
                currentLoad = kotlin.random.Random.nextInt(1000, 8000),
                averageQueryTimeMs = kotlin.random.Random.nextDouble(5.0, 50.0),
                isHealthy = true
            )
        }
    }

    private fun createShardingRouter(strategy: ShardingStrategy, shards: List<DatabaseShard>): ShardingRouter {
        return when (strategy.type) {
            ShardingType.RANGE_BASED -> RangeBasedShardingRouter(shards)
            ShardingType.HASH_BASED -> HashBasedShardingRouter(shards)
            ShardingType.DIRECTORY_BASED -> DirectoryBasedShardingRouter(shards)
            ShardingType.CONSISTENT_HASH -> ConsistentHashShardingRouter(shards)
            ShardingType.COMPOSITE -> CompositeShardingRouter(shards)
        }
    }

    private fun generateTestQueries(count: Int): List<DatabaseQuery> {
        return (1..count).map { queryId ->
            val queryType = QueryType.values().random()
            val isComplexQuery = kotlin.random.Random.nextDouble() < 0.3 // 30% ë³µì¡í•œ ì¿¼ë¦¬
            val affectedShards = if (isComplexQuery) kotlin.random.Random.nextInt(2, 4) else 1
            
            DatabaseQuery(
                id = "query-$queryId",
                type = queryType,
                shardKey = generateShardKey(queryType),
                affectedShards = affectedShards,
                isJoinQuery = isComplexQuery && kotlin.random.Random.nextBoolean(),
                estimatedComplexity = if (isComplexQuery) QueryComplexity.HIGH else QueryComplexity.LOW
            )
        }
    }

    private fun generateShardKey(queryType: QueryType): String {
        return when (queryType) {
            QueryType.SELECT -> "user-${kotlin.random.Random.nextInt(1, 10000)}"
            QueryType.INSERT -> "user-${kotlin.random.Random.nextInt(1, 10000)}"
            QueryType.UPDATE -> "user-${kotlin.random.Random.nextInt(1, 10000)}"
            QueryType.DELETE -> "user-${kotlin.random.Random.nextInt(1, 10000)}"
            QueryType.JOIN -> "join-${kotlin.random.Random.nextInt(1, 1000)}"
        }
    }

    private fun calculateShardingMetrics(
        results: List<QueryResult>,
        totalDurationMs: Long,
        shards: List<DatabaseShard>
    ): DatabaseShardingMetrics {
        val successfulResults = results.filter { it.success }
        val queryTimes = successfulResults.map { it.executionTimeNanos / 1_000_000.0 } // msë¡œ ë³€í™˜
        
        // ìƒ¤ë“œë³„ ì¿¼ë¦¬ ë¶„ë°° ë¶„ì„
        val shardDistribution = results.flatMap { result ->
            result.affectedShards.map { shardId -> shardId }
        }.groupBy { it }.mapValues { it.value.size }
        
        val totalQueries = shardDistribution.values.sum()
        val idealDistribution = totalQueries.toDouble() / shards.size
        val distributionVariance = shardDistribution.values.map { 
            (it - idealDistribution).pow(2) 
        }.average()
        val dataDistributionBalance = 100.0 - (sqrt(distributionVariance) / idealDistribution * 100).coerceAtMost(100.0)
        
        // í¬ë¡œìŠ¤ ìƒ¤ë“œ ì¿¼ë¦¬ ë¹„ìœ¨
        val crossShardQueries = results.count { it.crossShardOperation }
        val crossShardQueryRatio = (crossShardQueries.toDouble() / results.size) * 100
        
        // ìƒ¤ë“œ í™œìš©ë¥  ë¶„ì‚°
        val shardUtilizations = shards.map { shard ->
            val shardQueries = shardDistribution[shard.id] ?: 0
            shardQueries.toDouble() / shard.capacity * 100
        }
        val utilizationVariance = shardUtilizations.map { util ->
            (util - shardUtilizations.average()).pow(2)
        }.average()
        
        return DatabaseShardingMetrics(
            queryThroughputQps = successfulResults.size.toDouble() / (totalDurationMs / 1000.0),
            averageQueryLatencyMs = queryTimes.average(),
            dataDistributionBalance = dataDistributionBalance,
            crossShardQueryRatio = crossShardQueryRatio,
            shardUtilizationVariance = utilizationVariance
        )
    }

    private fun analyzeShardingResults(results: Map<String, DatabaseShardingMetrics>): DatabaseShardingAnalysis {
        val bestThroughput = results.maxByOrNull { it.value.queryThroughputQps }
        val bestLatency = results.minByOrNull { it.value.averageQueryLatencyMs }
        val bestDistribution = results.maxByOrNull { it.value.dataDistributionBalance }
        val lowestCrossShardRatio = results.minByOrNull { it.value.crossShardQueryRatio }
        
        // ì¢…í•© ì ìˆ˜ ê³„ì‚°
        val overallScores = results.mapValues { (_, metrics) ->
            val throughputScore = metrics.queryThroughputQps / results.values.maxOf { it.queryThroughputQps }
            val latencyScore = 1.0 - (metrics.averageQueryLatencyMs / results.values.maxOf { it.averageQueryLatencyMs })
            val distributionScore = metrics.dataDistributionBalance / 100.0
            val crossShardScore = 1.0 - (metrics.crossShardQueryRatio / 100.0)
            
            (throughputScore * 0.3 + latencyScore * 0.3 + distributionScore * 0.25 + crossShardScore * 0.15)
        }
        
        val bestOverall = overallScores.maxByOrNull { it.value }
        
        // ë°ì´í„° ë¶„ì‚° í’ˆì§ˆ í‰ê°€
        val avgDistributionBalance = results.values.map { it.dataDistributionBalance }.average()
        val dataDistributionQuality = when {
            avgDistributionBalance >= 90 -> "Excellent - ë°ì´í„°ê°€ ë§¤ìš° ê· ë“±í•˜ê²Œ ë¶„ì‚°ë¨"
            avgDistributionBalance >= 75 -> "Good - ë°ì´í„° ë¶„ì‚°ì´ ì–‘í˜¸í•¨"
            avgDistributionBalance >= 60 -> "Fair - ì¼ë¶€ ìƒ¤ë“œì— ë°ì´í„° í¸ì¤‘"
            else -> "Poor - ì‹¬ê°í•œ ë°ì´í„° ë¶ˆê· í˜•"
        }
        
        return DatabaseShardingAnalysis(
            bestShardingStrategy = bestOverall?.key ?: "HashSharding",
            dataDistributionQuality = dataDistributionQuality,
            overallRecommendation = when (bestOverall?.key) {
                "HashSharding" -> "ê· ë“±í•œ ë°ì´í„° ë¶„ì‚°ì„ ìœ„í•´ í•´ì‹œ ê¸°ë°˜ ìƒ¤ë”©ì´ ìµœì ì…ë‹ˆë‹¤"
                "RangeSharding" -> "ìˆœì°¨ì  ë°ì´í„° ì ‘ê·¼ íŒ¨í„´ì—ëŠ” ë²”ìœ„ ê¸°ë°˜ ìƒ¤ë”©ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤"
                "ConsistentHashSharding" -> "ë™ì  ìŠ¤ì¼€ì¼ë§ì´ í•„ìš”í•œ í™˜ê²½ì—ì„œëŠ” ì¼ê´€ì„± í•´ì‹œê°€ ì í•©í•©ë‹ˆë‹¤"
                "DirectorySharding" -> "ë³µì¡í•œ ì¿¼ë¦¬ íŒ¨í„´ì—ëŠ” ë””ë ‰í† ë¦¬ ê¸°ë°˜ ìƒ¤ë”©ì´ ìœ ì—°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤"
                else -> "í˜„ì¬ ì›Œí¬ë¡œë“œì—ëŠ” ${bestOverall?.key} ì „ëµì´ ê°€ì¥ ì í•©í•©ë‹ˆë‹¤"
            }
        )
    }

    private fun generateShardingRecommendations(results: Map<String, DatabaseShardingMetrics>): List<String> {
        val recommendations = mutableListOf<String>()
        
        val avgCrossShardRatio = results.values.map { it.crossShardQueryRatio }.average()
        val avgDistributionBalance = results.values.map { it.dataDistributionBalance }.average()
        val avgUtilizationVariance = results.values.map { it.shardUtilizationVariance }.average()
        
        if (avgCrossShardRatio > 30.0) {
            recommendations.add("í¬ë¡œìŠ¤ ìƒ¤ë“œ ì¿¼ë¦¬ ë¹„ìœ¨ì´ ${avgCrossShardRatio.toInt()}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ë°ì´í„° ëª¨ë¸ë§ì„ ì¬ê²€í† í•˜ì„¸ìš”")
        }
        
        if (avgDistributionBalance < 70.0) {
            recommendations.add("ë°ì´í„° ë¶„ì‚° ê· í˜•ì´ ë‚®ìŠµë‹ˆë‹¤. ìƒ¤ë“œ í‚¤ ì„ íƒì„ ì¬ê²€í† í•˜ê³  ë¦¬ìƒ¤ë”©ì„ ê³ ë ¤í•˜ì„¸ìš”")
        }
        
        if (avgUtilizationVariance > 500.0) {
            recommendations.add("ìƒ¤ë“œë³„ ë¶€í•˜ í¸ì°¨ê°€ í½ë‹ˆë‹¤. ë™ì  ë¦¬ë°¸ëŸ°ì‹± ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•˜ì„¸ìš”")
        }
        
        recommendations.add("ì •ê¸°ì ì¸ ìƒ¤ë“œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ìµœì  ë¶„ì‚° ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”")
        recommendations.add("ìƒ¤ë“œ í™•ì¥ ì‹œ ì¼ê´€ì„± í•´ì‹œ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê¸°ë°˜ ë°©ì‹ì„ ê³ ë ¤í•˜ì„¸ìš”")
        
        return recommendations
    }

    /**
     * 3ë‹¨ê³„: ë¶„ì‚° ìºì‹œ ê´€ë¦¬ ë¶„ì„
     */
    suspend fun analyzeDistributedCache(): DistributedCacheAnalysisResult = withContext(Dispatchers.IO) {
        println("ğŸ” Phase 3: Distributed Cache Management Analysis")
        
        val cacheStrategies = listOf(
            CacheStrategy("RedisCluster", CacheType.REDIS_CLUSTER),
            CacheStrategy("RedisReplication", CacheType.REDIS_REPLICATION),
            CacheStrategy("Hazelcast", CacheType.HAZELCAST),
            CacheStrategy("MemcachedCluster", CacheType.MEMCACHED_CLUSTER),
            CacheStrategy("ConsistentHashing", CacheType.CONSISTENT_HASHING)
        )
        
        val results = mutableMapOf<String, DistributedCacheMetrics>()
        
        for (strategy in cacheStrategies) {
            println("ğŸ“Š Testing ${strategy.name} cache strategy...")
            results[strategy.name] = measureCachePerformance(strategy)
        }
        
        val analysis = analyzeCacheResults(results)
        println("âœ… Distributed cache analysis completed")
        
        DistributedCacheAnalysisResult(
            cacheStrategies = results,
            analysis = analysis,
            recommendations = generateCacheRecommendations(results)
        )
    }

    private suspend fun measureCachePerformance(strategy: CacheStrategy): DistributedCacheMetrics {
        val cacheNodes = createTestCacheNodes(3) // 3ê°œ ìºì‹œ ë…¸ë“œ
        val cacheManager = createCacheManager(strategy, cacheNodes)
        
        val cacheOperations = generateCacheOperations(5000)
        val results = mutableListOf<CacheOperationResult>()
        
        // ìºì‹œ ì›Œë°ì—…
        repeat(500) {
            val warmupKey = "warmup-key-$it"
            val warmupValue = "warmup-value-$it"
            cacheManager.set(warmupKey, warmupValue)
        }
        
        // ì‹¤ì œ ì¸¡ì •
        val startTime = System.currentTimeMillis()
        
        cacheOperations.asFlow()
            .buffer(200) // ë™ì‹œ ì‘ì—… ì œí•œ
            .map { operation ->
                async {
                    val operationStartTime = System.nanoTime()
                    val result = when (operation.type) {
                        CacheOperationType.GET -> cacheManager.get(operation.key)
                        CacheOperationType.SET -> cacheManager.set(operation.key, operation.value)
                        CacheOperationType.DELETE -> cacheManager.delete(operation.key)
                        CacheOperationType.EXISTS -> cacheManager.exists(operation.key)
                    }
                    val operationEndTime = System.nanoTime()
                    
                    CacheOperationResult(
                        operationId = operation.id,
                        operationType = operation.type,
                        key = operation.key,
                        success = result.success,
                        hitResult = result.hit,
                        executionTimeNanos = operationEndTime - operationStartTime,
                        networkLatencyMs = result.networkLatencyMs
                    )
                }
            }
            .buffer(300)
            .collect { deferred ->
                results.add(deferred.await())
            }
        
        val endTime = System.currentTimeMillis()
        val totalDurationMs = endTime - startTime
        
        return calculateCacheMetrics(results, totalDurationMs, cacheNodes)
    }

    private fun createTestCacheNodes(count: Int): List<CacheNode> {
        return (1..count).map { nodeId ->
            CacheNode(
                id = "cache-node-$nodeId",
                host = "192.168.1.$nodeId",
                port = 6379 + nodeId,
                capacity = 1000000, // 1M entries
                currentSize = kotlin.random.Random.nextInt(100000, 800000),
                averageLatencyMs = kotlin.random.Random.nextDouble(0.5, 5.0),
                isHealthy = true,
                replicationRole = when (nodeId) {
                    1 -> ReplicationRole.MASTER
                    else -> ReplicationRole.SLAVE
                }
            )
        }
    }

    private fun createCacheManager(strategy: CacheStrategy, nodes: List<CacheNode>): CacheManager {
        return when (strategy.type) {
            CacheType.REDIS_CLUSTER -> RedisClusterCacheManager(nodes)
            CacheType.REDIS_REPLICATION -> RedisReplicationCacheManager(nodes)
            CacheType.HAZELCAST -> HazelcastCacheManager(nodes)
            CacheType.MEMCACHED_CLUSTER -> MemcachedClusterCacheManager(nodes)
            CacheType.CONSISTENT_HASHING -> ConsistentHashingCacheManager(nodes)
        }
    }

    private fun generateCacheOperations(count: Int): List<CacheOperation> {
        val keys = (1..1000).map { "key-$it" }
        
        return (1..count).map { operationId ->
            val operationType = when (kotlin.random.Random.nextDouble()) {
                in 0.0..0.6 -> CacheOperationType.GET // 60% GET
                in 0.6..0.85 -> CacheOperationType.SET // 25% SET
                in 0.85..0.95 -> CacheOperationType.EXISTS // 10% EXISTS
                else -> CacheOperationType.DELETE // 5% DELETE
            }
            
            val key = keys.random()
            val value = if (operationType == CacheOperationType.SET) {
                "value-for-$key-${System.currentTimeMillis()}"
            } else null
            
            CacheOperation(
                id = "op-$operationId",
                type = operationType,
                key = key,
                value = value
            )
        }
    }

    private fun calculateCacheMetrics(
        results: List<CacheOperationResult>,
        totalDurationMs: Long,
        cacheNodes: List<CacheNode>
    ): DistributedCacheMetrics {
        val successfulResults = results.filter { it.success }
        val getOperations = results.filter { it.operationType == CacheOperationType.GET }
        val hits = getOperations.filter { it.hitResult }
        
        val hitRatio = if (getOperations.isNotEmpty()) {
            (hits.size.toDouble() / getOperations.size) * 100
        } else 0.0
        
        val operationTimes = successfulResults.map { it.executionTimeNanos / 1_000_000.0 } // ms
        val networkLatencies = results.map { it.networkLatencyMs }
        
        // ì¼ê´€ì„± ë ˆë²¨ ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
        val consistencyLevel = calculateConsistencyLevel(results, cacheNodes)
        
        // ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ ê³„ì‚°
        val networkOverhead = networkLatencies.average()
        
        return DistributedCacheMetrics(
            hitRatio = hitRatio,
            averageLatencyMs = operationTimes.average(),
            throughputOps = successfulResults.size.toDouble() / (totalDurationMs / 1000.0),
            consistencyLevel = consistencyLevel,
            networkOverhead = networkOverhead
        )
    }

    private fun calculateConsistencyLevel(
        results: List<CacheOperationResult>,
        cacheNodes: List<CacheNode>
    ): Double {
        // ì‹œë®¬ë ˆì´ì…˜: ë§ˆìŠ¤í„°-ìŠ¬ë ˆì´ë¸Œ ë³µì œ ì§€ì—° ê¸°ë°˜ ì¼ê´€ì„± ê³„ì‚°
        val masterNode = cacheNodes.find { it.replicationRole == ReplicationRole.MASTER }
        val slaveNodes = cacheNodes.filter { it.replicationRole == ReplicationRole.SLAVE }
        
        if (masterNode == null || slaveNodes.isEmpty()) {
            return 100.0 // ë‹¨ì¼ ë…¸ë“œëŠ” ì™„ì „ ì¼ê´€ì„±
        }
        
        // ë³µì œ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜ (0.1ms ~ 10ms)
        val replicationDelayMs = kotlin.random.Random.nextDouble(0.1, 10.0)
        val totalOperations = results.size
        val writeOperations = results.filter { 
            it.operationType == CacheOperationType.SET || it.operationType == CacheOperationType.DELETE 
        }.size
        
        // ë³µì œ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ì¼ê´€ì„± ì €í•˜ ê³„ì‚°
        val inconsistentReads = (writeOperations * (replicationDelayMs / 100.0)).toInt()
        val consistencyLevel = ((totalOperations - inconsistentReads).toDouble() / totalOperations) * 100
        
        return consistencyLevel.coerceIn(85.0, 100.0) // 85~100% ë²”ìœ„
    }

    private fun analyzeCacheResults(results: Map<String, DistributedCacheMetrics>): DistributedCacheAnalysis {
        val bestHitRatio = results.maxByOrNull { it.value.hitRatio }
        val bestLatency = results.minByOrNull { it.value.averageLatencyMs }
        val bestThroughput = results.maxByOrNull { it.value.throughputOps }
        val bestConsistency = results.maxByOrNull { it.value.consistencyLevel }
        
        // ì¢…í•© ì ìˆ˜ ê³„ì‚°
        val overallScores = results.mapValues { (_, metrics) ->
            val hitRatioScore = metrics.hitRatio / 100.0
            val latencyScore = 1.0 - (metrics.averageLatencyMs / results.values.maxOf { it.averageLatencyMs })
            val throughputScore = metrics.throughputOps / results.values.maxOf { it.throughputOps }
            val consistencyScore = metrics.consistencyLevel / 100.0
            val networkScore = 1.0 - (metrics.networkOverhead / results.values.maxOf { it.networkOverhead })
            
            (hitRatioScore * 0.25 + latencyScore * 0.25 + throughputScore * 0.25 + 
             consistencyScore * 0.15 + networkScore * 0.1)
        }
        
        val bestOverall = overallScores.maxByOrNull { it.value }
        
        // ì¼ê´€ì„± vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„
        val avgConsistency = results.values.map { it.consistencyLevel }.average()
        val avgLatency = results.values.map { it.averageLatencyMs }.average()
        
        val consistencyTradeoff = when {
            avgConsistency >= 98 && avgLatency <= 2.0 -> "High consistency with excellent performance"
            avgConsistency >= 95 && avgLatency <= 5.0 -> "Good balance between consistency and performance"
            avgConsistency >= 90 -> "Acceptable consistency, optimized for performance"
            else -> "Performance optimized, eventual consistency"
        }
        
        return DistributedCacheAnalysis(
            bestCacheStrategy = bestOverall?.key ?: "RedisCluster",
            consistencyTradeoff = consistencyTradeoff,
            overallRecommendation = when (bestOverall?.key) {
                "RedisCluster" -> "ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ ìë™ ìƒ¤ë”©ì´ í•„ìš”í•œ í™˜ê²½ì— ìµœì "
                "RedisReplication" -> "ì½ê¸° ì§‘ì•½ì  ì›Œí¬ë¡œë“œì—ì„œ ì¼ê´€ì„±ì´ ì¤‘ìš”í•œ ê²½ìš° ì í•©"
                "Hazelcast" -> "ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ìºì‹±ê³¼ ë¶„ì‚° ì»´í“¨íŒ…ì— íš¨ê³¼ì "
                "ConsistentHashing" -> "ë™ì  í™•ì¥ì„±ì´ ì¤‘ìš”í•œ ëŒ€ê·œëª¨ í™˜ê²½ì— ì í•©"
                else -> "í˜„ì¬ ì›Œí¬ë¡œë“œì—ëŠ” ${bestOverall?.key} ì „ëµì´ ê°€ì¥ íš¨ê³¼ì "
            }
        )
    }

    private fun generateCacheRecommendations(results: Map<String, DistributedCacheMetrics>): List<String> {
        val recommendations = mutableListOf<String>()
        
        val avgHitRatio = results.values.map { it.hitRatio }.average()
        val avgLatency = results.values.map { it.averageLatencyMs }.average()
        val avgConsistency = results.values.map { it.consistencyLevel }.average()
        val avgNetworkOverhead = results.values.map { it.networkOverhead }.average()
        
        if (avgHitRatio < 80.0) {
            recommendations.add("ìºì‹œ ì ì¤‘ë¥ ì´ ${avgHitRatio.toInt()}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. TTL ì„¤ì •ê³¼ ìºì‹œ í‚¤ ì „ëµì„ ì¬ê²€í† í•˜ì„¸ìš”")
        }
        
        if (avgLatency > 5.0) {
            recommendations.add("í‰ê·  ì§€ì—°ì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤. ìºì‹œ ë…¸ë“œë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ë” ê°€ê¹ê²Œ ë°°ì¹˜í•˜ì„¸ìš”")
        }
        
        if (avgConsistency < 95.0) {
            recommendations.add("ë°ì´í„° ì¼ê´€ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. ë³µì œ ì „ëµì„ ê°•í™”í•˜ê±°ë‚˜ ë™ê¸° ë³µì œë¥¼ ê³ ë ¤í•˜ì„¸ìš”")
        }
        
        if (avgNetworkOverhead > 10.0) {
            recommendations.add("ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œê°€ ë†’ìŠµë‹ˆë‹¤. ë°ì´í„° ì••ì¶•ì´ë‚˜ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í™œìš©í•˜ì„¸ìš”")
        }
        
        recommendations.add("ìºì‹œ í¬ê¸°ì™€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì •ê¸°ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”")
        recommendations.add("ìºì‹œ ë¬´íš¨í™” ì „ëµì„ ì›Œí¬ë¡œë“œ íŒ¨í„´ì— ë§ê²Œ ìµœì í™”í•˜ì„¸ìš”")
        
        return recommendations
    }

    /**
     * 4ë‹¨ê³„: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í†µì‹  ì„±ëŠ¥ ë¶„ì„
     */
    suspend fun analyzeMicroserviceCommunication(): MicroserviceCommunicationAnalysisResult = withContext(Dispatchers.IO) {
        println("ğŸ” Phase 4: Microservice Communication Performance Analysis")
        
        val communicationPatterns = listOf(
            CommunicationPattern("HTTPSynchronous", CommunicationType.HTTP_SYNC),
            CommunicationPattern("HTTPAsynchronous", CommunicationType.HTTP_ASYNC),
            CommunicationPattern("gRPCUnary", CommunicationType.GRPC_UNARY),
            CommunicationPattern("gRPCStreaming", CommunicationType.GRPC_STREAMING),
            CommunicationPattern("MessageQueue", CommunicationType.MESSAGE_QUEUE),
            CommunicationPattern("EventStreaming", CommunicationType.EVENT_STREAMING)
        )
        
        val results = mutableMapOf<String, MicroserviceCommunicationMetrics>()
        
        for (pattern in communicationPatterns) {
            println("ğŸ“Š Testing ${pattern.name} communication pattern...")
            results[pattern.name] = measureCommunicationPerformance(pattern)
        }
        
        val analysis = analyzeCommunicationResults(results)
        println("âœ… Microservice communication analysis completed")
        
        MicroserviceCommunicationAnalysisResult(
            communicationPatterns = results,
            analysis = analysis,
            recommendations = generateCommunicationRecommendations(results)
        )
    }

    private suspend fun measureCommunicationPerformance(pattern: CommunicationPattern): MicroserviceCommunicationMetrics {
        val microservices = createTestMicroservices(5) // 5ê°œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤
        val communicationManager = createCommunicationManager(pattern, microservices)
        
        val requests = generateMicroserviceRequests(3000)
        val results = mutableListOf<CommunicationResult>()
        
        // ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ ì›Œë°ì—…
        repeat(100) {
            val service = microservices.random()
            communicationManager.discoverService(service.name)
        }
        
        // ì‹¤ì œ ì¸¡ì •
        val startTime = System.currentTimeMillis()
        
        requests.asFlow()
            .buffer(150) // ë™ì‹œ ìš”ì²­ ì œí•œ
            .map { request ->
                async {
                    val requestStartTime = System.nanoTime()
                    val discoveryStartTime = System.nanoTime()
                    
                    // ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬
                    val targetService = communicationManager.discoverService(request.targetService)
                    val discoveryEndTime = System.nanoTime()
                    
                    // ì‹¤ì œ í†µì‹ 
                    val communicationStartTime = System.nanoTime()
                    val result = communicationManager.sendRequest(request, targetService)
                    val communicationEndTime = System.nanoTime()
                    
                    val requestEndTime = System.nanoTime()
                    
                    CommunicationResult(
                        requestId = request.id,
                        targetService = request.targetService,
                        success = result.success,
                        totalLatencyNanos = requestEndTime - requestStartTime,
                        serviceDiscoveryLatencyNanos = discoveryEndTime - discoveryStartTime,
                        communicationLatencyNanos = communicationEndTime - communicationStartTime,
                        circuitBreakerTriggered = result.circuitBreakerTriggered,
                        retryCount = result.retryCount
                    )
                }
            }
            .buffer(200)
            .collect { deferred ->
                results.add(deferred.await())
            }
        
        val endTime = System.currentTimeMillis()
        val totalDurationMs = endTime - startTime
        
        return calculateCommunicationMetrics(results, totalDurationMs, microservices)
    }

    private fun createTestMicroservices(count: Int): List<Microservice> {
        val serviceTypes = listOf("user-service", "order-service", "payment-service", "inventory-service", "notification-service")
        
        return (1..count).map { serviceId ->
            val serviceType = serviceTypes[(serviceId - 1) % serviceTypes.size]
            
            Microservice(
                id = "service-$serviceId",
                name = "$serviceType-$serviceId",
                host = "192.168.1.$serviceId",
                port = 8080 + serviceId,
                healthEndpoint = "/actuator/health",
                averageResponseTimeMs = kotlin.random.Random.nextDouble(10.0, 200.0),
                errorRate = kotlin.random.Random.nextDouble(0.0, 0.05), // 0-5% ì—ëŸ¬ìœ¨
                isHealthy = true,
                currentLoad = kotlin.random.Random.nextInt(10, 90),
                circuitBreakerState = CircuitBreakerState.CLOSED
            )
        }
    }

    private fun createCommunicationManager(
        pattern: CommunicationPattern, 
        services: List<Microservice>
    ): CommunicationManager {
        return when (pattern.type) {
            CommunicationType.HTTP_SYNC -> HTTPSyncCommunicationManager(services)
            CommunicationType.HTTP_ASYNC -> HTTPAsyncCommunicationManager(services)
            CommunicationType.GRPC_UNARY -> GRPCUnaryCommunicationManager(services)
            CommunicationType.GRPC_STREAMING -> GRPCStreamingCommunicationManager(services)
            CommunicationType.MESSAGE_QUEUE -> MessageQueueCommunicationManager(services)
            CommunicationType.EVENT_STREAMING -> EventStreamingCommunicationManager(services)
        }
    }

    private fun generateMicroserviceRequests(count: Int): List<MicroserviceRequest> {
        val services = listOf("user-service", "order-service", "payment-service", "inventory-service", "notification-service")
        
        return (1..count).map { requestId ->
            val requestType = MicroserviceRequestType.values().random()
            val payloadSize = when (requestType) {
                MicroserviceRequestType.QUERY -> kotlin.random.Random.nextInt(100, 1000) // ì‘ì€ ì¿¼ë¦¬
                MicroserviceRequestType.COMMAND -> kotlin.random.Random.nextInt(500, 5000) // ì¤‘ê°„ í¬ê¸° ëª…ë ¹
                MicroserviceRequestType.BATCH -> kotlin.random.Random.nextInt(5000, 50000) // í° ë°°ì¹˜ ì‘ì—…
                MicroserviceRequestType.STREAMING -> kotlin.random.Random.nextInt(1000, 10000) // ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°
            }
            
            MicroserviceRequest(
                id = "req-$requestId",
                targetService = services.random(),
                requestType = requestType,
                payloadSize = payloadSize,
                expectedResponseTime = when (requestType) {
                    MicroserviceRequestType.QUERY -> kotlin.random.Random.nextLong(10, 100)
                    MicroserviceRequestType.COMMAND -> kotlin.random.Random.nextLong(50, 500)
                    MicroserviceRequestType.BATCH -> kotlin.random.Random.nextLong(500, 5000)
                    MicroserviceRequestType.STREAMING -> kotlin.random.Random.nextLong(100, 1000)
                },
                requiresAuth = kotlin.random.Random.nextBoolean(),
                priority = RequestPriority.values().random()
            )
        }
    }

    private fun calculateCommunicationMetrics(
        results: List<CommunicationResult>,
        totalDurationMs: Long,
        microservices: List<Microservice>
    ): MicroserviceCommunicationMetrics {
        val successfulResults = results.filter { it.success }
        val failedResults = results.filter { !it.success }
        
        val totalLatencies = successfulResults.map { it.totalLatencyNanos / 1_000_000.0 } // ms
        val serviceDiscoveryLatencies = results.map { it.serviceDiscoveryLatencyNanos / 1_000_000.0 } // ms
        val communicationLatencies = successfulResults.map { it.communicationLatencyNanos / 1_000_000.0 } // ms
        
        val circuitBreakerTriggers = results.count { it.circuitBreakerTriggered }
        val totalRetries = results.sumOf { it.retryCount }
        
        return MicroserviceCommunicationMetrics(
            requestThroughputRps = successfulResults.size.toDouble() / (totalDurationMs / 1000.0),
            averageLatencyMs = totalLatencies.average(),
            errorRate = (failedResults.size.toDouble() / results.size) * 100,
            circuitBreakerTriggerRate = (circuitBreakerTriggers.toDouble() / results.size) * 100,
            serviceDiscoveryLatencyMs = serviceDiscoveryLatencies.average(),
            averageRetryCount = if (results.isNotEmpty()) totalRetries.toDouble() / results.size else 0.0,
            p95LatencyMs = if (totalLatencies.isNotEmpty()) {
                totalLatencies.sorted()[(totalLatencies.size * 0.95).toInt()]
            } else 0.0,
            p99LatencyMs = if (totalLatencies.isNotEmpty()) {
                totalLatencies.sorted()[(totalLatencies.size * 0.99).toInt()]
            } else 0.0
        )
    }

    private fun analyzeCommunicationResults(results: Map<String, MicroserviceCommunicationMetrics>): MicroserviceCommunicationAnalysis {
        val bestThroughput = results.maxByOrNull { it.value.requestThroughputRps }
        val bestLatency = results.minByOrNull { it.value.averageLatencyMs }
        val lowestErrorRate = results.minByOrNull { it.value.errorRate }
        val bestReliability = results.minByOrNull { it.value.circuitBreakerTriggerRate }
        
        // ì¢…í•© ì ìˆ˜ ê³„ì‚°
        val overallScores = results.mapValues { (_, metrics) ->
            val throughputScore = metrics.requestThroughputRps / results.values.maxOf { it.requestThroughputRps }
            val latencyScore = 1.0 - (metrics.averageLatencyMs / results.values.maxOf { it.averageLatencyMs })
            val errorScore = 1.0 - (metrics.errorRate / 100.0)
            val reliabilityScore = 1.0 - (metrics.circuitBreakerTriggerRate / 100.0)
            val discoveryScore = 1.0 - (metrics.serviceDiscoveryLatencyMs / results.values.maxOf { it.serviceDiscoveryLatencyMs })
            
            (throughputScore * 0.25 + latencyScore * 0.25 + errorScore * 0.2 + 
             reliabilityScore * 0.2 + discoveryScore * 0.1)
        }
        
        val bestOverall = overallScores.maxByOrNull { it.value }
        
        // ì‹ ë¢°ì„± í‰ê°€
        val avgErrorRate = results.values.map { it.errorRate }.average()
        val avgCircuitBreakerRate = results.values.map { it.circuitBreakerTriggerRate }.average()
        
        val reliabilityAssessment = when {
            avgErrorRate < 1.0 && avgCircuitBreakerRate < 2.0 -> "Excellent - ë§¤ìš° ì•ˆì •ì ì¸ í†µì‹ "
            avgErrorRate < 3.0 && avgCircuitBreakerRate < 5.0 -> "Good - ì•ˆì •ì ì¸ í†µì‹ "
            avgErrorRate < 5.0 && avgCircuitBreakerRate < 10.0 -> "Fair - ì¼ë¶€ ì•ˆì •ì„± ë¬¸ì œ"
            else -> "Poor - ì‹¬ê°í•œ ì•ˆì •ì„± ë¬¸ì œ"
        }
        
        return MicroserviceCommunicationAnalysis(
            bestCommunicationPattern = bestOverall?.key ?: "gRPCUnary",
            reliabilityAssessment = reliabilityAssessment,
            overallRecommendation = when (bestOverall?.key) {
                "gRPCUnary" -> "ë†’ì€ ì„±ëŠ¥ê³¼ íƒ€ì… ì•ˆì •ì„±ì´ í•„ìš”í•œ ì„œë¹„ìŠ¤ ê°„ í†µì‹ ì— ìµœì "
                "gRPCStreaming" -> "ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ì´ë‚˜ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì „ì†¡ì— ì í•©"
                "HTTPAsynchronous" -> "ë…¼ë¸”ë¡œí‚¹ ì²˜ë¦¬ê°€ ì¤‘ìš”í•œ ê³ ë¶€í•˜ í™˜ê²½ì— íš¨ê³¼ì "
                "MessageQueue" -> "ë¹„ë™ê¸° ì²˜ë¦¬ì™€ ë‚´ê²°í•¨ì„±ì´ ì¤‘ìš”í•œ ì‹œìŠ¤í…œì— ì í•©"
                "EventStreaming" -> "ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ ì‹¤ì‹œê°„ ì²˜ë¦¬ì— ìµœì "
                else -> "í˜„ì¬ ì›Œí¬ë¡œë“œì—ëŠ” ${bestOverall?.key} íŒ¨í„´ì´ ê°€ì¥ íš¨ê³¼ì "
            }
        )
    }

    private fun generateCommunicationRecommendations(results: Map<String, MicroserviceCommunicationMetrics>): List<String> {
        val recommendations = mutableListOf<String>()
        
        val avgLatency = results.values.map { it.averageLatencyMs }.average()
        val avgErrorRate = results.values.map { it.errorRate }.average()
        val avgCircuitBreakerRate = results.values.map { it.circuitBreakerTriggerRate }.average()
        val avgServiceDiscoveryLatency = results.values.map { it.serviceDiscoveryLatencyMs }.average()
        val avgRetryCount = results.values.map { it.averageRetryCount }.average()
        
        if (avgLatency > 100.0) {
            recommendations.add("í‰ê·  ì‘ë‹µì‹œê°„ì´ ${avgLatency.toInt()}msë¡œ ë†’ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìµœì í™”ë‚˜ ìºì‹±ì„ ê³ ë ¤í•˜ì„¸ìš”")
        }
        
        if (avgErrorRate > 2.0) {
            recommendations.add("ì—ëŸ¬ìœ¨ì´ ${avgErrorRate.toInt()}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì¬ì‹œë„ ì •ì±…ê³¼ íšŒë¡œ ì°¨ë‹¨ê¸° ì„¤ì •ì„ ê²€í† í•˜ì„¸ìš”")
        }
        
        if (avgCircuitBreakerRate > 5.0) {
            recommendations.add("íšŒë¡œ ì°¨ë‹¨ê¸° ë°œë™ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ ì•ˆì •ì„±ê³¼ íƒ€ì„ì•„ì›ƒ ì„¤ì •ì„ ì ê²€í•˜ì„¸ìš”")
        }
        
        if (avgServiceDiscoveryLatency > 10.0) {
            recommendations.add("ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ ì§€ì—°ì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤. ìºì‹±ì´ë‚˜ ë¡œì»¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ í™œìš©í•˜ì„¸ìš”")
        }
        
        if (avgRetryCount > 1.5) {
            recommendations.add("ì¬ì‹œë„ íšŸìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤. ë°±ì˜¤í”„ ì „ëµê³¼ ì¬ì‹œë„ í•œê³„ë¥¼ ì¡°ì •í•˜ì„¸ìš”")
        }
        
        recommendations.add("ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ í†µì‹  ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ì—¬ ë³‘ëª©ì§€ì ì„ ì‹ë³„í•˜ì„¸ìš”")
        recommendations.add("ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš”ë„ì— ë”°ë¥¸ SLA ì •ì˜ ë° ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¼ìš°íŒ…ì„ êµ¬í˜„í•˜ì„¸ìš”")
        
        return recommendations
    }

    /**
     * 5ë‹¨ê³„: ì‹œìŠ¤í…œ ë³µì›ë ¥ ë¶„ì„ (êµ¬í˜„ ì˜ˆì •)
     */
    suspend fun analyzeSystemResilience(): SystemResilienceAnalysisResult {
        println("ğŸ” Phase 5: System Resilience Analysis")
        
        val scenarios = listOf(
            ResilienceScenario("ServiceFailure", "ì„œë¹„ìŠ¤ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤", FailureType.SERVICE_UNAVAILABLE),
            ResilienceScenario("DatabaseFailure", "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨", FailureType.DATABASE_CONNECTION),
            ResilienceScenario("NetworkPartition", "ë„¤íŠ¸ì›Œí¬ ë¶„í• ", FailureType.NETWORK_PARTITION),
            ResilienceScenario("MemoryPressure", "ë©”ëª¨ë¦¬ ë¶€ì¡±", FailureType.RESOURCE_EXHAUSTION),
            ResilienceScenario("CascadingFailure", "ì—°ì‡„ ì¥ì• ", FailureType.CASCADING_FAILURE)
        )
        
        val results = mutableMapOf<String, ResilienceMetrics>()
        
        for (scenario in scenarios) {
            println("ğŸ“Š Testing ${scenario.name} resilience scenario...")
            results[scenario.name] = measureResilienceMetrics(scenario)
        }
        
        val analysis = analyzeResilienceResults(results)
        println("âœ… System resilience analysis completed")
        
        return SystemResilienceAnalysisResult(
            resilienceMetrics = results,
            analysis = analysis,
            recommendations = generateResilienceRecommendations(results)
        )
    }

    /**
     * ì „ì²´ ë¶„ì„ ê²°ê³¼ ì¢…í•©
     */
    private fun generateOverallAnalysis(
        loadBalancing: LoadBalancingAnalysisResult,
        databaseSharding: DatabaseShardingAnalysisResult,
        distributedCache: DistributedCacheAnalysisResult,
        microserviceCommunication: MicroserviceCommunicationAnalysisResult,
        systemResilience: SystemResilienceAnalysisResult
    ): OverallDistributedSystemAnalysis {
        
        return OverallDistributedSystemAnalysis(
            overallScore = 85.0, // ê³„ì‚° ë¡œì§ ì¶”ê°€ ì˜ˆì •
            keyFindings = listOf(
                "ë¶„ì‚° ì‹œìŠ¤í…œ ë¶„ì„ ê¸°ë³¸ êµ¬ì¡° ì™„ì„±",
                "5ê°œ í•µì‹¬ ì˜ì—­ ë¶„ì„ í”„ë ˆì„ì›Œí¬ êµ¬ì¶•",
                "ì¢…í•© ì„±ëŠ¥ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬ì„±"
            ),
            recommendations = listOf(
                "ê° ë¶„ì„ ëª¨ë“ˆì˜ êµ¬ì²´ì  êµ¬í˜„ í•„ìš”",
                "ì‹¤ì œ ë¶„ì‚° í™˜ê²½ì—ì„œì˜ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰",
                "ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„ ë¡œì§ êµ¬í˜„"
            ),
            priorityOptimizations = listOf(
                "ë¡œë“œ ë°¸ëŸ°ì‹± ì „ëµ ìµœì í™”",
                "ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© íš¨ìœ¨ì„± ê°œì„ ",
                "ë¶„ì‚° ìºì‹œ ì¼ê´€ì„± ë³´ì¥"
            )
        )
    }

    // ì‹œìŠ¤í…œ ë³µì›ë ¥ ë¶„ì„ ì§€ì› ë©”ì„œë“œë“¤
    private suspend fun measureResilienceMetrics(scenario: ResilienceScenario): ResilienceMetrics {
        val startTime = System.nanoTime()
        
        // ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜
        val results = mutableListOf<ResilienceTestResult>()
        
        repeat(100) { iteration ->
            val testResult = simulateFailureScenario(scenario, iteration)
            results.add(testResult)
        }
        
        val endTime = System.nanoTime()
        val totalDurationMs = (endTime - startTime) / 1_000_000
        
        return calculateResilienceMetrics(results, totalDurationMs, scenario)
    }
    
    private fun simulateFailureScenario(scenario: ResilienceScenario, iteration: Int): ResilienceTestResult {
        val operationStartTime = System.nanoTime()
        
        val result = when (scenario.failureType) {
            FailureType.SERVICE_UNAVAILABLE -> {
                // ì„œë¹„ìŠ¤ ê°€ìš©ì„± ì¥ì•  ì‹œë®¬ë ˆì´ì…˜
                val isServiceDown = kotlin.random.Random.nextDouble() < 0.2 // 20% ì¥ì• ìœ¨
                ResilienceTestResult(
                    testId = "${scenario.name}-$iteration",
                    operationType = "service_call",
                    success = !isServiceDown,
                    executionTimeMs = if (isServiceDown) 5000 else kotlin.random.Random.nextDouble(50.0, 200.0),
                    errorType = if (isServiceDown) "SERVICE_TIMEOUT" else null,
                    retryCount = if (isServiceDown) 3 else 0,
                    circuitBreakerTriggered = isServiceDown
                )
            }
            FailureType.DATABASE_CONNECTION -> {
                // ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¥ì•  ì‹œë®¬ë ˆì´ì…˜
                val connectionFails = kotlin.random.Random.nextDouble() < 0.15 // 15% ì—°ê²° ì‹¤íŒ¨
                ResilienceTestResult(
                    testId = "${scenario.name}-$iteration",
                    operationType = "database_query",
                    success = !connectionFails,
                    executionTimeMs = if (connectionFails) 3000 else kotlin.random.Random.nextDouble(10.0, 100.0),
                    errorType = if (connectionFails) "CONNECTION_TIMEOUT" else null,
                    retryCount = if (connectionFails) 2 else 0,
                    circuitBreakerTriggered = false
                )
            }
            FailureType.NETWORK_PARTITION -> {
                // ë„¤íŠ¸ì›Œí¬ ë¶„í•  ì‹œë®¬ë ˆì´ì…˜
                val partitionOccurs = kotlin.random.Random.nextDouble() < 0.1 // 10% ë¶„í•  í™•ë¥ 
                ResilienceTestResult(
                    testId = "${scenario.name}-$iteration",
                    operationType = "network_call",
                    success = !partitionOccurs,
                    executionTimeMs = if (partitionOccurs) 10000 else kotlin.random.Random.nextDouble(100.0, 500.0),
                    errorType = if (partitionOccurs) "NETWORK_PARTITION" else null,
                    retryCount = if (partitionOccurs) 5 else 0,
                    circuitBreakerTriggered = partitionOccurs
                )
            }
            FailureType.RESOURCE_EXHAUSTION -> {
                // ë¦¬ì†ŒìŠ¤ ê³ ê°ˆ ì‹œë®¬ë ˆì´ì…˜
                val resourceExhausted = kotlin.random.Random.nextDouble() < 0.25 // 25% ë¦¬ì†ŒìŠ¤ ë¶€ì¡±
                ResilienceTestResult(
                    testId = "${scenario.name}-$iteration",
                    operationType = "resource_allocation",
                    success = !resourceExhausted,
                    executionTimeMs = if (resourceExhausted) 2000 else kotlin.random.Random.nextDouble(20.0, 150.0),
                    errorType = if (resourceExhausted) "OUT_OF_MEMORY" else null,
                    retryCount = if (resourceExhausted) 1 else 0,
                    circuitBreakerTriggered = false
                )
            }
            FailureType.CASCADING_FAILURE -> {
                // ì—°ì‡„ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜
                val cascadeFailure = kotlin.random.Random.nextDouble() < 0.08 // 8% ì—°ì‡„ ì¥ì• 
                ResilienceTestResult(
                    testId = "${scenario.name}-$iteration",
                    operationType = "cascading_call",
                    success = !cascadeFailure,
                    executionTimeMs = if (cascadeFailure) 8000 else kotlin.random.Random.nextDouble(80.0, 300.0),
                    errorType = if (cascadeFailure) "CASCADING_FAILURE" else null,
                    retryCount = if (cascadeFailure) 4 else 0,
                    circuitBreakerTriggered = cascadeFailure
                )
            }
        }
        
        val operationEndTime = System.nanoTime()
        return result.copy(executionTimeMs = (operationEndTime - operationStartTime) / 1_000_000.0)
    }
    
    private fun calculateResilienceMetrics(
        results: List<ResilienceTestResult>,
        totalDurationMs: Long,
        scenario: ResilienceScenario
    ): ResilienceMetrics {
        val successRate = (results.count { it.success }.toDouble() / results.size) * 100
        val averageLatency = results.map { it.executionTimeMs }.average()
        val totalRetries = results.sumOf { it.retryCount }
        val circuitBreakerTriggers = results.count { it.circuitBreakerTriggered }
        
        val mttr = calculateMeanTimeToRecovery(results)  // í‰ê·  ë³µêµ¬ ì‹œê°„
        val mtbf = calculateMeanTimeBetweenFailures(results)  // í‰ê·  ì¥ì•  ê°„ê²©
        val availability = calculateAvailability(successRate, mttr, mtbf)
        
        return ResilienceMetrics(
            scenarioName = scenario.name,
            successRate = successRate,
            averageLatencyMs = averageLatency,
            totalRetries = totalRetries,
            circuitBreakerTriggers = circuitBreakerTriggers,
            meanTimeToRecoveryMs = mttr,
            meanTimeBetweenFailuresMs = mtbf,
            availabilityPercentage = availability,
            resilienceScore = calculateResilienceScore(successRate, mttr, availability)
        )
    }
    
    private fun calculateMeanTimeToRecovery(results: List<ResilienceTestResult>): Double {
        val failureResults = results.filter { !it.success }
        return if (failureResults.isNotEmpty()) {
            failureResults.map { it.executionTimeMs }.average()
        } else {
            0.0
        }
    }
    
    private fun calculateMeanTimeBetweenFailures(results: List<ResilienceTestResult>): Double {
        val failures = results.withIndex().filter { !it.value.success }
        if (failures.size <= 1) return Double.MAX_VALUE
        
        val intervals = mutableListOf<Int>()
        for (i in 1 until failures.size) {
            intervals.add(failures[i].index - failures[i-1].index)
        }
        
        return intervals.average() * 100.0 // ê°€ì •: ê° í…ŒìŠ¤íŠ¸ëŠ” 100ms ê°„ê²©
    }
    
    private fun calculateAvailability(successRate: Double, mttr: Double, mtbf: Double): Double {
        return if (mttr > 0 && mtbf > 0) {
            (mtbf / (mtbf + mttr)) * 100
        } else {
            successRate
        }
    }
    
    private fun calculateResilienceScore(successRate: Double, mttr: Double, availability: Double): Double {
        val successWeight = 0.4
        val recoveryWeight = 0.3  // ë‚®ì€ MTTRì´ ì¢‹ìŒ
        val availabilityWeight = 0.3
        
        val recoveryScore = if (mttr > 0) {
            (1.0 - (mttr / 10000.0)).coerceIn(0.0, 1.0) * 100
        } else {
            100.0
        }
        
        return (successRate * successWeight + recoveryScore * recoveryWeight + availability * availabilityWeight)
            .coerceIn(0.0, 100.0)
    }
    
    private fun analyzeResilienceResults(results: Map<String, ResilienceMetrics>): SystemResilienceAnalysis {
        val bestScenario = results.maxByOrNull { it.value.resilienceScore }
        val worstScenario = results.minByOrNull { it.value.resilienceScore }
        val avgScore = results.values.map { it.resilienceScore }.average()
        
        val overallGrade = when {
            avgScore >= 90 -> "A+ (Excellent)"
            avgScore >= 80 -> "A (Very Good)"
            avgScore >= 70 -> "B (Good)"
            avgScore >= 60 -> "C (Acceptable)"
            else -> "D (Needs Improvement)"
        }
        
        val keyInsights = buildList {
            add("í‰ê·  ë³µì›ë ¥ ì ìˆ˜: ${String.format("%.1f", avgScore)} ($overallGrade)")
            bestScenario?.let { 
                add("ìµœê³  ì„±ëŠ¥ ì‹œë‚˜ë¦¬ì˜¤: ${it.key} (${String.format("%.1f", it.value.resilienceScore)}ì )")
            }
            worstScenario?.let {
                add("ê°œì„  í•„ìš” ì‹œë‚˜ë¦¬ì˜¤: ${it.key} (${String.format("%.1f", it.value.resilienceScore)}ì )")
            }
            
            val highRetryScenarios = results.filter { it.value.totalRetries > 200 }
            if (highRetryScenarios.isNotEmpty()) {
                add("ë†’ì€ ì¬ì‹œë„ìœ¨ ì‹œë‚˜ë¦¬ì˜¤: ${highRetryScenarios.keys.joinToString()}")
            }
            
            val circuitBreakerScenarios = results.filter { it.value.circuitBreakerTriggers > 5 }
            if (circuitBreakerScenarios.isNotEmpty()) {
                add("ì„œí‚· ë¸Œë ˆì´ì»¤ ë¹ˆë°œ ë™ì‘: ${circuitBreakerScenarios.keys.joinToString()}")
            }
        }
        
        return SystemResilienceAnalysis(
            overallGrade = overallGrade,
            averageScore = avgScore,
            keyInsights = keyInsights.joinToString("\n")
        )
    }
    
    private fun generateResilienceRecommendations(results: Map<String, ResilienceMetrics>): List<String> {
        val recommendations = mutableListOf<String>()
        
        results.forEach { (scenarioName, metrics) ->
            when {
                metrics.successRate < 80 -> {
                    recommendations.add("$scenarioName: ì„±ê³µë¥ ì´ ë‚®ìŠµë‹ˆë‹¤ (${String.format("%.1f", metrics.successRate)}%). ì¬ì‹œë„ ë¡œì§ê³¼ ì¥ì•  ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ì„ ê°•í™”í•˜ì„¸ìš”.")
                }
                metrics.meanTimeToRecoveryMs > 3000 -> {
                    recommendations.add("$scenarioName: ë³µêµ¬ ì‹œê°„ì´ ê¸¸ìŠµë‹ˆë‹¤ (${String.format("%.0f", metrics.meanTimeToRecoveryMs)}ms). ìë™ ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°œì„ í•˜ì„¸ìš”.")
                }
                metrics.circuitBreakerTriggers > 10 -> {
                    recommendations.add("$scenarioName: ì„œí‚· ë¸Œë ˆì´ì»¤ê°€ ìì£¼ ë™ì‘í•©ë‹ˆë‹¤ (${metrics.circuitBreakerTriggers}íšŒ). ì„ê³„ê°’ê³¼ ë³µêµ¬ ì „ëµì„ ì¡°ì •í•˜ì„¸ìš”.")
                }
                metrics.availabilityPercentage < 99 -> {
                    recommendations.add("$scenarioName: ê°€ìš©ì„±ì´ ë‚®ìŠµë‹ˆë‹¤ (${String.format("%.2f", metrics.availabilityPercentage)}%). ì´ì¤‘í™”ì™€ ë¡œë“œ ë°¸ëŸ°ì‹±ì„ ê²€í† í•˜ì„¸ìš”.")
                }
                metrics.resilienceScore >= 95 -> {
                    recommendations.add("$scenarioName: ìš°ìˆ˜í•œ ë³µì›ë ¥ì„ ë³´ì…ë‹ˆë‹¤ (${String.format("%.1f", metrics.resilienceScore)}ì ). í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
                }
            }
        }
        
        // ì „ì²´ì ì¸ ê¶Œì¥ì‚¬í•­
        val avgScore = results.values.map { it.resilienceScore }.average()
        when {
            avgScore < 70 -> {
                recommendations.add("ì „ì²´ì ì¸ ì‹œìŠ¤í…œ ë³µì›ë ¥ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. Circuit Breaker, Bulkhead, Timeout íŒ¨í„´ì„ ì ê·¹ ë„ì…í•˜ì„¸ìš”.")
                recommendations.add("ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ë³„ ëŒ€ì‘ í”Œë ˆì´ë¶ì„ ì‘ì„±í•˜ê³  ì •ê¸°ì ì¸ ì¹´ì˜¤ìŠ¤ ì—”ì§€ë‹ˆì–´ë§ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
            }
            avgScore < 85 -> {
                recommendations.add("ì‹œìŠ¤í…œ ë³µì›ë ¥ì´ ì–‘í˜¸í•˜ì§€ë§Œ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ê³¼ ì•Œë¦¼ ì²´ê³„ë¥¼ ê°•í™”í•˜ì„¸ìš”.")
            }
            else -> {
                recommendations.add("ìš°ìˆ˜í•œ ì‹œìŠ¤í…œ ë³µì›ë ¥ì„ ë³´ì…ë‹ˆë‹¤. í˜„ì¬ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ë©° ì§€ì†ì ì¸ ê°œì„ ì„ ì§„í–‰í•˜ì„¸ìš”.")
            }
        }
        
        return recommendations
    }
}

// ================================
// ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜
// ================================

// ë¡œë“œ ë°¸ëŸ°ì‹± ê´€ë ¨
data class LoadBalancingAnalysisResult(
    val strategies: Map<String, LoadBalancingMetrics>,
    val analysis: LoadBalancingAnalysis,
    val recommendations: List<String>
)

data class LoadBalancingMetrics(
    val throughputRps: Double = 0.0,
    val averageLatencyMs: Double = 0.0,
    val distributionEfficiency: Double = 0.0,
    val failoverTimeMs: Long = 0,
    val healthCheckLatencyMs: Double = 0.0
)

data class LoadBalancingAnalysis(
    val bestStrategy: String,
    val worstStrategy: String,
    val overallRecommendation: String
)

// ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© ê´€ë ¨
data class DatabaseShardingAnalysisResult(
    val strategies: Map<String, DatabaseShardingMetrics>,
    val analysis: DatabaseShardingAnalysis,
    val recommendations: List<String>
)

data class DatabaseShardingMetrics(
    val queryThroughputQps: Double = 0.0,
    val averageQueryLatencyMs: Double = 0.0,
    val dataDistributionBalance: Double = 0.0,
    val crossShardQueryRatio: Double = 0.0,
    val shardUtilizationVariance: Double = 0.0
)

data class DatabaseShardingAnalysis(
    val bestShardingStrategy: String,
    val dataDistributionQuality: String,
    val overallRecommendation: String
)

// ë¶„ì‚° ìºì‹œ ê´€ë ¨
data class DistributedCacheAnalysisResult(
    val cacheStrategies: Map<String, DistributedCacheMetrics>,
    val analysis: DistributedCacheAnalysis,
    val recommendations: List<String>
)

data class DistributedCacheMetrics(
    val hitRatio: Double = 0.0,
    val averageLatencyMs: Double = 0.0,
    val throughputOps: Double = 0.0,
    val consistencyLevel: Double = 0.0,
    val networkOverhead: Double = 0.0
)

data class DistributedCacheAnalysis(
    val bestCacheStrategy: String,
    val consistencyTradeoff: String,
    val overallRecommendation: String
)

// ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í†µì‹  ê´€ë ¨
data class MicroserviceCommunicationAnalysisResult(
    val communicationPatterns: Map<String, MicroserviceCommunicationMetrics>,
    val analysis: MicroserviceCommunicationAnalysis,
    val recommendations: List<String>
)

data class MicroserviceCommunicationMetrics(
    val requestThroughputRps: Double = 0.0,
    val averageLatencyMs: Double = 0.0,
    val errorRate: Double = 0.0,
    val circuitBreakerTriggerRate: Double = 0.0,
    val serviceDiscoveryLatencyMs: Double = 0.0
)

data class MicroserviceCommunicationAnalysis(
    val bestCommunicationPattern: String,
    val reliabilityAssessment: String,
    val overallRecommendation: String
)

// ì‹œìŠ¤í…œ ë³µì›ë ¥ ê´€ë ¨
data class SystemResilienceAnalysisResult(
    val resilienceMetrics: Map<String, SystemResilienceMetrics>,
    val analysis: SystemResilienceAnalysis,
    val recommendations: List<String>
)

data class SystemResilienceMetrics(
    val availabilityPercent: Double = 0.0,
    val mttr: Duration = Duration.ZERO, // Mean Time To Recovery
    val mtbf: Duration = Duration.ZERO, // Mean Time Between Failures
    val degradationRecoveryTimeMs: Long = 0,
    val cascadeFailureResistance: Double = 0.0
)

data class SystemResilienceAnalysis(
    val overallResilience: String,
    val weakestPoints: String,
    val overallRecommendation: String
)

// ì „ì²´ ë¶„ì„ ê²°ê³¼
data class OverallDistributedSystemAnalysis(
    val overallScore: Double,
    val keyFindings: List<String>,
    val recommendations: List<String>,
    val priorityOptimizations: List<String>
)

data class ComprehensiveDistributedAnalysisResult(
    val loadBalancing: LoadBalancingAnalysisResult,
    val databaseSharding: DatabaseShardingAnalysisResult,
    val distributedCache: DistributedCacheAnalysisResult,
    val microserviceCommunication: MicroserviceCommunicationAnalysisResult,
    val systemResilience: SystemResilienceAnalysisResult,
    val overallAnalysis: OverallDistributedSystemAnalysis,
    val executionTimeMs: Long
)

// ================================
// ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© ì§€ì› í´ë˜ìŠ¤ë“¤
// ================================

enum class ShardingType {
    RANGE_BASED, HASH_BASED, DIRECTORY_BASED, CONSISTENT_HASH, COMPOSITE
}

enum class QueryType {
    SELECT, INSERT, UPDATE, DELETE, JOIN
}

enum class QueryComplexity {
    LOW, MEDIUM, HIGH
}

data class ShardingStrategy(
    val name: String,
    val type: ShardingType
)

data class DatabaseShard(
    val id: String,
    val partitionRange: String,
    val capacity: Int,
    var currentLoad: Int,
    val averageQueryTimeMs: Double,
    var isHealthy: Boolean = true
)

data class DatabaseQuery(
    val id: String,
    val type: QueryType,
    val shardKey: String,
    val affectedShards: Int,
    val isJoinQuery: Boolean = false,
    val estimatedComplexity: QueryComplexity = QueryComplexity.LOW
)

data class QueryRoutingResult(
    val affectedShards: List<String>,
    val success: Boolean,
    val estimatedExecutionTimeMs: Long = kotlin.random.Random.nextLong(1, 100)
)

data class QueryResult(
    val queryId: String,
    val affectedShards: List<String>,
    val executionTimeNanos: Long,
    val success: Boolean,
    val crossShardOperation: Boolean
)

// ìƒ¤ë”© ë¼ìš°í„° ì¸í„°í˜ì´ìŠ¤ ë° êµ¬í˜„
abstract class ShardingRouter(protected val shards: List<DatabaseShard>) {
    abstract suspend fun routeQuery(query: DatabaseQuery): QueryRoutingResult
    
    protected fun selectShardByHash(shardKey: String): DatabaseShard {
        val hash = shardKey.hashCode()
        val shardIndex = Math.abs(hash) % shards.size
        return shards[shardIndex]
    }
    
    protected fun selectShardByRange(shardKey: String): DatabaseShard {
        // ì‚¬ìš©ì ID ê¸°ë°˜ ë²”ìœ„ ë¶„ë°° (user-1234 í˜•íƒœ)
        val userId = shardKey.substringAfter("-").toIntOrNull() ?: 0
        return when {
            userId < 2500 -> shards[0]
            userId < 5000 -> shards[1]
            userId < 7500 -> shards[2]
            else -> shards[3]
        }
    }
}

class RangeBasedShardingRouter(shards: List<DatabaseShard>) : ShardingRouter(shards) {
    override suspend fun routeQuery(query: DatabaseQuery): QueryRoutingResult {
        val targetShard = selectShardByRange(query.shardKey)
        
        if (!targetShard.isHealthy) {
            return QueryRoutingResult(emptyList(), false)
        }
        
        val executionTime = (targetShard.averageQueryTimeMs * 
            when (query.estimatedComplexity) {
                QueryComplexity.LOW -> 1.0
                QueryComplexity.MEDIUM -> 2.0
                QueryComplexity.HIGH -> 4.0
            }).toLong()
        
        delay(executionTime)
        
        return QueryRoutingResult(
            affectedShards = listOf(targetShard.id),
            success = true,
            estimatedExecutionTimeMs = executionTime
        )
    }
}

class HashBasedShardingRouter(shards: List<DatabaseShard>) : ShardingRouter(shards) {
    override suspend fun routeQuery(query: DatabaseQuery): QueryRoutingResult {
        val targetShard = selectShardByHash(query.shardKey)
        
        if (!targetShard.isHealthy) {
            return QueryRoutingResult(emptyList(), false)
        }
        
        val executionTime = (targetShard.averageQueryTimeMs * 
            when (query.estimatedComplexity) {
                QueryComplexity.LOW -> 1.0
                QueryComplexity.MEDIUM -> 2.0
                QueryComplexity.HIGH -> 4.0
            }).toLong()
        
        delay(executionTime)
        
        return QueryRoutingResult(
            affectedShards = listOf(targetShard.id),
            success = true,
            estimatedExecutionTimeMs = executionTime
        )
    }
}

// ================================
// ë¡œë“œ ë°¸ëŸ°ì‹± ì§€ì› í´ë˜ìŠ¤ë“¤
// ================================

enum class LoadBalancingType {
    ROUND_ROBIN, WEIGHTED_ROUND_ROBIN, LEAST_CONNECTIONS, 
    LEAST_RESPONSE_TIME, IP_HASH, RANDOM
}

data class LoadBalancingStrategy(
    val name: String,
    val type: LoadBalancingType
)

data class ServerNode(
    val id: String,
    val weight: Double,
    val capacity: Int,
    var currentConnections: Int,
    val averageResponseTimeMs: Double,
    var isHealthy: Boolean = true
)

data class TestRequest(
    val id: Int,
    val size: Int,
    val clientIP: String = "192.168.1.${kotlin.random.Random.nextInt(1, 255)}"
)

data class RoutingResult(
    val serverNode: String,
    val success: Boolean,
    val responseTimeMs: Long = kotlin.random.Random.nextLong(10, 200)
)

data class RequestResult(
    val requestId: Int,
    val serverNode: String,
    val responseTimeNanos: Long,
    val success: Boolean
)

// ë¡œë“œ ë°¸ëŸ°ì„œ ì¸í„°í˜ì´ìŠ¤ ë° êµ¬í˜„
abstract class LoadBalancer(protected val nodes: List<ServerNode>) {
    abstract suspend fun routeRequest(request: TestRequest): RoutingResult
}

class RoundRobinLoadBalancer(nodes: List<ServerNode>) : LoadBalancer(nodes) {
    private var currentIndex = 0
    
    override suspend fun routeRequest(request: TestRequest): RoutingResult {
        val healthyNodes = nodes.filter { it.isHealthy }
        if (healthyNodes.isEmpty()) {
            return RoutingResult("", false)
        }
        
        val selectedNode = healthyNodes[currentIndex % healthyNodes.size]
        currentIndex = (currentIndex + 1) % healthyNodes.size
        
        // ìš”ì²­ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        delay(selectedNode.averageResponseTimeMs.toLong())
        
        return RoutingResult(
            serverNode = selectedNode.id,
            success = true,
            responseTimeMs = selectedNode.averageResponseTimeMs.toLong()
        )
    }
}

class WeightedRoundRobinLoadBalancer(nodes: List<ServerNode>) : LoadBalancer(nodes) {
    private val weightedNodes = mutableListOf<ServerNode>()
    
    init {
        // ê°€ì¤‘ì¹˜ì— ë”°ë¼ ë…¸ë“œ ë³µì œ
        nodes.forEach { node ->
            repeat(node.weight.toInt()) {
                weightedNodes.add(node)
            }
        }
    }
    
    private var currentIndex = 0
    
    override suspend fun routeRequest(request: TestRequest): RoutingResult {
        val healthyWeightedNodes = weightedNodes.filter { it.isHealthy }
        if (healthyWeightedNodes.isEmpty()) {
            return RoutingResult("", false)
        }
        
        val selectedNode = healthyWeightedNodes[currentIndex % healthyWeightedNodes.size]
        currentIndex = (currentIndex + 1) % healthyWeightedNodes.size
        
        delay(selectedNode.averageResponseTimeMs.toLong())
        
        return RoutingResult(
            serverNode = selectedNode.id,
            success = true,
            responseTimeMs = selectedNode.averageResponseTimeMs.toLong()
        )
    }
}

class LeastConnectionsLoadBalancer(nodes: List<ServerNode>) : LoadBalancer(nodes) {
    override suspend fun routeRequest(request: TestRequest): RoutingResult {
        val healthyNodes = nodes.filter { it.isHealthy }
        if (healthyNodes.isEmpty()) {
            return RoutingResult("", false)
        }
        
        val selectedNode = healthyNodes.minByOrNull { it.currentConnections }!!
        selectedNode.currentConnections++
        
        delay(selectedNode.averageResponseTimeMs.toLong())
        
        // ìš”ì²­ ì™„ë£Œ í›„ ì—°ê²° ìˆ˜ ê°ì†Œ
        selectedNode.currentConnections = maxOf(0, selectedNode.currentConnections - 1)
        
        return RoutingResult(
            serverNode = selectedNode.id,
            success = true,
            responseTimeMs = selectedNode.averageResponseTimeMs.toLong()
        )
    }
}

class LeastResponseTimeLoadBalancer(nodes: List<ServerNode>) : LoadBalancer(nodes) {
    override suspend fun routeRequest(request: TestRequest): RoutingResult {
        val healthyNodes = nodes.filter { it.isHealthy }
        if (healthyNodes.isEmpty()) {
            return RoutingResult("", false)
        }
        
        val selectedNode = healthyNodes.minByOrNull { it.averageResponseTimeMs }!!
        
        delay(selectedNode.averageResponseTimeMs.toLong())
        
        return RoutingResult(
            serverNode = selectedNode.id,
            success = true,
            responseTimeMs = selectedNode.averageResponseTimeMs.toLong()
        )
    }
}

class IPHashLoadBalancer(nodes: List<ServerNode>) : LoadBalancer(nodes) {
    override suspend fun routeRequest(request: TestRequest): RoutingResult {
        val healthyNodes = nodes.filter { it.isHealthy }
        if (healthyNodes.isEmpty()) {
            return RoutingResult("", false)
        }
        
        val hash = request.clientIP.hashCode()
        val selectedNode = healthyNodes[Math.abs(hash) % healthyNodes.size]
        
        delay(selectedNode.averageResponseTimeMs.toLong())
        
        return RoutingResult(
            serverNode = selectedNode.id,
            success = true,
            responseTimeMs = selectedNode.averageResponseTimeMs.toLong()
        )
    }
}

class RandomLoadBalancer(nodes: List<ServerNode>) : LoadBalancer(nodes) {
    override suspend fun routeRequest(request: TestRequest): RoutingResult {
        val healthyNodes = nodes.filter { it.isHealthy }
        if (healthyNodes.isEmpty()) {
            return RoutingResult("", false)
        }
        
        val selectedNode = healthyNodes.random()
        
        delay(selectedNode.averageResponseTimeMs.toLong())
        
        return RoutingResult(
            serverNode = selectedNode.id,
            success = true,
            responseTimeMs = selectedNode.averageResponseTimeMs.toLong()
        )
    }
}

// ì‹œìŠ¤í…œ ë³µì›ë ¥ ë¶„ì„ ê´€ë ¨
data class SystemResilienceAnalysisResult(
    val resilienceMetrics: Map<String, ResilienceMetrics>,
    val analysis: SystemResilienceAnalysis,
    val recommendations: List<String>
)

data class ResilienceScenario(
    val name: String,
    val description: String,
    val failureType: FailureType
)

enum class FailureType {
    SERVICE_UNAVAILABLE,
    DATABASE_CONNECTION,
    NETWORK_PARTITION,
    RESOURCE_EXHAUSTION,
    CASCADING_FAILURE
}

data class ResilienceTestResult(
    val testId: String,
    val operationType: String,
    val success: Boolean,
    val executionTimeMs: Double,
    val errorType: String?,
    val retryCount: Int,
    val circuitBreakerTriggered: Boolean
)

data class ResilienceMetrics(
    val scenarioName: String,
    val successRate: Double,
    val averageLatencyMs: Double,
    val totalRetries: Int,
    val circuitBreakerTriggers: Int,
    val meanTimeToRecoveryMs: Double,
    val meanTimeBetweenFailuresMs: Double,
    val availabilityPercentage: Double,
    val resilienceScore: Double
)

data class SystemResilienceAnalysis(
    val overallGrade: String,
    val averageScore: Double,
    val keyInsights: String
)